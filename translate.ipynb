{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQAr7eBswD9TfVJy5cU8l7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kritdanai044/translate/blob/main/translate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r-I7Lypk18Mk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a434cb6-4b86-49c7-b257-cd18b554b08a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.8.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,990 kB]\n",
            "Get:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,546 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,323 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,422 kB]\n",
            "Get:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [913 kB]\n",
            "Get:19 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [48.3 kB]\n",
            "Fetched 11.5 MB in 4s (2,717 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown\n",
        "!apt-get update                                                                          # อัพเดท Package ทั้งหมดใน VM ตัวนี้\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install translators --upgrade\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP5Psm-dIkc3",
        "outputId": "eed22677-5127-4c7a-e3fe-c59586858e41"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting translators\n",
            "  Downloading translators-5.4.2-py3-none-any.whl (29 kB)\n",
            "Collecting PyExecJS>=1.5.1\n",
            "  Downloading PyExecJS-1.5.1.tar.gz (13 kB)\n",
            "Collecting requests>=2.28.1\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting pathos>=0.2.9\n",
            "  Downloading pathos-0.2.9-py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.7/dist-packages (from translators) (4.9.1)\n",
            "Collecting loguru>=0.6.0\n",
            "  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill>=0.3.5.1 in /usr/local/lib/python3.7/dist-packages (from pathos>=0.2.9->translators) (0.3.5.1)\n",
            "Collecting multiprocess>=0.70.13\n",
            "  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 55.4 MB/s \n",
            "\u001b[?25hCollecting pox>=0.3.1\n",
            "  Downloading pox-0.3.1-py2.py3-none-any.whl (28 kB)\n",
            "Collecting ppft>=1.7.6.5\n",
            "  Downloading ppft-1.7.6.5-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.7.3 in /usr/local/lib/python3.7/dist-packages (from ppft>=1.7.6.5->pathos>=0.2.9->translators) (1.15.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.28.1->translators) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.28.1->translators) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.28.1->translators) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.28.1->translators) (2022.6.15)\n",
            "Building wheels for collected packages: PyExecJS\n",
            "  Building wheel for PyExecJS (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyExecJS: filename=PyExecJS-1.5.1-py3-none-any.whl size=14598 sha256=78713c1d703ed503f45ad40fa125ce16d2727ea6d74de086f4b3bd39da53f258\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/ee/03/da5c0b4a8c13362beeb844eb913bbe58a89bde1de2b9157007\n",
            "Successfully built PyExecJS\n",
            "Installing collected packages: ppft, pox, multiprocess, requests, PyExecJS, pathos, loguru, translators\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "Successfully installed PyExecJS-1.5.1 loguru-0.6.0 multiprocess-0.70.13 pathos-0.2.9 pox-0.3.1 ppft-1.7.6.5 requests-2.28.1 translators-5.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import translators as ts\n",
        "import gdown\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ofgQ0BA5IqWc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4c0a652-631f-469a-b2b8-72c76ea84546"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using state South Carolina server backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "phrase = 'The quick brown fox jumps over the lazy dog.'\n",
        "ts.google(phrase, from_language='en', to_language='th')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uB5qkzkpI7zu",
        "outputId": "2b704c1a-f00a-40b4-ddac-cb53a9f8b9cb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'สุนัขจิ้งจอกสีน้ำตาลเร็วกระโดดข้ามสุนัขขี้เกียจ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1FSkLW5ixIrjJZkVTpbftPOeN_2bzRA7y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIkWHKwyJN3H",
        "outputId": "f31a99a0-7729-4c64-bac3-cbf40223f52b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1FSkLW5ixIrjJZkVTpbftPOeN_2bzRA7y\n",
            "To: /content/translate.zip\n",
            "100% 219M/219M [00:02<00:00, 93.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip translate.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kkdDDkoJY41",
        "outputId": "334ba28e-3b62-443e-c809-157c74a8278b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  translate.zip\n",
            "  inflating: lan_to_language.json    \n",
            "  inflating: sentences.csv           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_l2l = pd.read_json(\"/content/lan_to_language.json\", )\n",
        "df_sen = pd.read_csv(\"/content/sentences.csv\")"
      ],
      "metadata": {
        "id": "kVvCV-YHKNS-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "lYuvNNbPL7zz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('/content/lan_to_language.json')"
      ],
      "metadata": {
        "id": "1hJRc8UkMJ-n"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = json.load(f)"
      ],
      "metadata": {
        "id": "YtYj-Y_NL-ig"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qey7lPClMT4l",
        "outputId": "8b5cb602-c4db-47bd-dc6e-afb38e6d6c72"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cmn': 'Mandarin Chinese',\n",
              " 'deu': 'German',\n",
              " 'rus': 'Russian',\n",
              " 'fra': 'French',\n",
              " 'eng': 'English',\n",
              " 'jpn': 'Japanese',\n",
              " 'spa': 'Spanish',\n",
              " 'ita': 'Italian',\n",
              " 'kor': 'Korean',\n",
              " 'vie': 'Vietnamese',\n",
              " 'nld': 'Dutch',\n",
              " 'epo': 'Esperanto',\n",
              " 'por': 'Portuguese',\n",
              " 'tur': 'Turkish',\n",
              " 'heb': 'Hebrew',\n",
              " 'hun': 'Hungarian',\n",
              " 'ell': 'Modern Greek (1453-)',\n",
              " 'ind': 'Indonesian',\n",
              " 'ara': 'Arabic',\n",
              " 'arz': 'Egyptian Arabic',\n",
              " 'fin': 'Finnish',\n",
              " 'bul': 'Bulgarian',\n",
              " 'yue': 'Yue Chinese',\n",
              " 'swe': 'Swedish',\n",
              " 'ukr': 'Ukrainian',\n",
              " 'bel': 'Belarusian',\n",
              " 'que': 'Quechua',\n",
              " 'ces': 'Czech',\n",
              " 'swh': 'Swahili (individual language)',\n",
              " 'nno': 'Norwegian Nynorsk',\n",
              " 'wuu': 'Wu Chinese',\n",
              " 'nob': 'Norwegian Bokmål',\n",
              " 'zsm': 'Standard Malay',\n",
              " 'est': 'Estonian',\n",
              " 'kat': 'Georgian',\n",
              " 'pol': 'Polish',\n",
              " 'lat': 'Latin',\n",
              " 'urd': 'Urdu',\n",
              " 'sqi': 'Albanian',\n",
              " 'isl': 'Icelandic',\n",
              " 'fry': 'Western Frisian',\n",
              " 'afr': 'Afrikaans',\n",
              " 'ron': 'Romanian',\n",
              " 'fao': 'Faroese',\n",
              " 'san': 'Sanskrit',\n",
              " 'bre': 'Breton',\n",
              " 'tat': 'Tatar',\n",
              " 'yid': 'Yiddish',\n",
              " 'uig': 'Uighur',\n",
              " 'uzb': 'Uzbek',\n",
              " 'srp': 'Serbian',\n",
              " 'qya': 'Quenya',\n",
              " 'dan': 'Danish',\n",
              " 'pes': 'Iranian Persian',\n",
              " 'slk': 'Slovak',\n",
              " 'eus': 'Basque',\n",
              " 'cycl': 'CycL',\n",
              " 'acm': 'Mesopotamian Arabic',\n",
              " 'tgl': 'Tagalog',\n",
              " 'lvs': 'Standard Latvian',\n",
              " 'kaz': 'Kazakh',\n",
              " 'hye': 'Armenian',\n",
              " 'hin': 'Hindi',\n",
              " 'lit': 'Lithuanian',\n",
              " 'ben': 'Bengali',\n",
              " 'cat': 'Catalan',\n",
              " 'bos': 'Bosnian',\n",
              " 'hrv': 'Croatian',\n",
              " 'tha': 'Thai',\n",
              " 'orv': 'Old Russian',\n",
              " 'cha': 'Chamorro',\n",
              " 'mon': 'Mongolian',\n",
              " 'lzh': 'Literary Chinese',\n",
              " 'scn': 'Sicilian',\n",
              " 'gle': 'Irish',\n",
              " 'mkd': 'Macedonian',\n",
              " 'slv': 'Slovenian',\n",
              " 'frm': 'Middle French (ca. 1400-1600)',\n",
              " 'glg': 'Galician',\n",
              " 'vol': 'Volapük',\n",
              " 'ain': 'Ainu (Japan)',\n",
              " 'jbo': 'Lojban',\n",
              " 'tok': 'Toki Pona',\n",
              " 'ina': 'Interlingua (International Auxiliary Language Association)',\n",
              " 'nds': 'Low German',\n",
              " 'mal': 'Malayalam',\n",
              " 'tlh': 'Klingon',\n",
              " 'roh': 'Romansh',\n",
              " 'ltz': 'Luxembourgish',\n",
              " 'oss': 'Ossetian',\n",
              " 'ido': 'Ido',\n",
              " 'gla': 'Scottish Gaelic',\n",
              " 'mlt': 'Maltese',\n",
              " 'sco': 'Scots',\n",
              " 'ast': 'Asturian',\n",
              " 'jav': 'Javanese',\n",
              " 'oci': 'Occitan (post 1500)',\n",
              " 'ile': 'Interlingue',\n",
              " 'ota': 'Ottoman Turkish (1500-1928)',\n",
              " 'xal': 'Kalmyk',\n",
              " 'tel': 'Telugu',\n",
              " 'sjn': 'Sindarin',\n",
              " 'nov': 'Novial',\n",
              " 'khm': 'Central Khmer',\n",
              " 'tpi': 'Tok Pisin',\n",
              " 'ang': 'Old English (ca. 450-1100)',\n",
              " 'aze': 'Azerbaijani',\n",
              " 'tgk': 'Tajik',\n",
              " 'tuk': 'Turkmen',\n",
              " 'chv': 'Chuvash',\n",
              " 'hsb': 'Upper Sorbian',\n",
              " 'dsb': 'Lower Sorbian',\n",
              " 'bod': 'Tibetan',\n",
              " 'sme': 'Northern Sami',\n",
              " 'cym': 'Welsh',\n",
              " 'mri': 'Maori',\n",
              " 'ksh': 'Kölsch',\n",
              " 'kmr': 'Northern Kurdish',\n",
              " 'ewe': 'Ewe',\n",
              " 'kab': 'Kabyle',\n",
              " 'ber': 'Berber languages',\n",
              " 'tpw': 'Tupí',\n",
              " 'udm': 'Udmurt',\n",
              " 'lld': 'Ladin',\n",
              " 'pms': 'Piemontese',\n",
              " 'lad': 'Ladino',\n",
              " 'grn': 'Guarani',\n",
              " 'mlg': 'Malagasy',\n",
              " 'xho': 'Xhosa',\n",
              " 'pnb': 'Western Panjabi',\n",
              " 'grc': 'Ancient Greek (to 1453)',\n",
              " 'hat': 'Haitian',\n",
              " 'lao': 'Lao',\n",
              " 'npi': 'Nepali (individual language)',\n",
              " 'cor': 'Cornish',\n",
              " 'nah': 'Nahuatl',\n",
              " 'avk': 'Kotava',\n",
              " 'mar': 'Marathi',\n",
              " 'guj': 'Gujarati',\n",
              " 'pan': 'Panjabi',\n",
              " 'kir': 'Kirghiz',\n",
              " 'myv': 'Erzya',\n",
              " 'prg': 'Prussian',\n",
              " 'sux': 'Sumerian',\n",
              " 'crs': 'Seselwa Creole French',\n",
              " 'ckt': 'Chukot',\n",
              " 'bak': 'Bashkir',\n",
              " 'zlm': 'Malay (individual language)',\n",
              " 'hil': 'Hiligaynon',\n",
              " 'cbk': 'Chavacano',\n",
              " 'chr': 'Cherokee',\n",
              " 'nav': 'Navajo',\n",
              " 'lkt': 'Lakota',\n",
              " 'enm': 'Middle English (1100-1500)',\n",
              " 'arq': 'Algerian Arabic',\n",
              " 'lin': 'Lingala',\n",
              " 'abk': 'Abkhazian',\n",
              " 'pcd': 'Picard',\n",
              " 'rom': 'Romany',\n",
              " 'gsw': 'Swiss German',\n",
              " 'tam': 'Tamil',\n",
              " 'zul': 'Zulu',\n",
              " 'awa': 'Awadhi',\n",
              " 'wln': 'Walloon',\n",
              " 'amh': 'Amharic',\n",
              " 'bar': 'Bavarian',\n",
              " 'hbo': 'Ancient Hebrew',\n",
              " 'mhr': 'Eastern Mari',\n",
              " 'bho': 'Bhojpuri',\n",
              " 'mrj': 'Western Mari',\n",
              " 'ckb': 'Central Kurdish',\n",
              " 'osx': 'Old Saxon',\n",
              " 'pfl': 'Pfaelzisch',\n",
              " 'mgm': 'Mambae',\n",
              " 'sna': 'Shona',\n",
              " 'mah': 'Marshallese',\n",
              " 'hau': 'Hausa',\n",
              " 'kan': 'Kannada',\n",
              " 'nog': 'Nogai',\n",
              " 'sin': 'Sinhala',\n",
              " 'glv': 'Manx',\n",
              " 'dng': 'Dungan',\n",
              " 'kal': 'Kalaallisut',\n",
              " 'liv': 'Liv',\n",
              " 'vro': 'Võro',\n",
              " 'apc': 'North Levantine Arabic',\n",
              " 'jdt': 'Judeo-Tat',\n",
              " 'fur': 'Friulian',\n",
              " 'che': 'Chechen',\n",
              " 'haw': 'Hawaiian',\n",
              " 'yor': 'Yoruba',\n",
              " 'crh': 'Crimean Tatar',\n",
              " 'pdc': 'Pennsylvania German',\n",
              " 'ppl': 'Pipil',\n",
              " 'kin': 'Kinyarwanda',\n",
              " 'shs': 'Shuswap',\n",
              " 'mnw': 'Mon',\n",
              " 'tet': 'Tetum',\n",
              " 'sah': 'Yakut',\n",
              " 'kum': 'Kumyk',\n",
              " 'ngt': 'Ngeq',\n",
              " 'nya': 'Nyanja',\n",
              " 'pus': 'Pushto',\n",
              " 'hif': 'Fiji Hindi',\n",
              " 'mya': 'Burmese',\n",
              " 'moh': 'Mohawk',\n",
              " 'wol': 'Wolof',\n",
              " 'tir': 'Tigrinya',\n",
              " 'ton': 'Tonga (Tonga Islands)',\n",
              " 'lzz': 'Laz',\n",
              " 'oar': 'Old Aramaic (up to 700 BCE)',\n",
              " 'lug': 'Ganda',\n",
              " 'brx': 'Bodo (India)',\n",
              " 'non': 'Old Norse',\n",
              " 'mww': 'Hmong Daw',\n",
              " 'hak': 'Hakka Chinese',\n",
              " 'nlv': 'Orizaba Nahuatl',\n",
              " 'ngu': 'Guerrero Nahuatl',\n",
              " 'bua': 'Buriat',\n",
              " 'aym': 'Aymara',\n",
              " 'vec': 'Venetian',\n",
              " 'ibo': 'Igbo',\n",
              " 'tkl': 'Tokelau',\n",
              " 'bam': 'Bambara',\n",
              " 'kha': 'Khasi',\n",
              " 'ceb': 'Cebuano',\n",
              " 'lou': 'Louisiana Creole',\n",
              " 'fuc': 'Pulaar',\n",
              " 'smo': 'Samoan',\n",
              " 'gag': 'Gagauz',\n",
              " 'lfn': 'Lingua Franca Nova',\n",
              " 'arg': 'Aragonese',\n",
              " 'umb': 'Umbundu',\n",
              " 'tyv': 'Tuvinian',\n",
              " 'kjh': 'Khakas',\n",
              " 'oji': 'Ojibwa',\n",
              " 'cyo': 'Cuyonon',\n",
              " 'urh': 'Urhobo',\n",
              " 'kzj': 'Coastal Kadazan',\n",
              " 'pam': 'Pampanga',\n",
              " 'srd': 'Sardinian',\n",
              " 'lmo': 'Lombard',\n",
              " 'swg': 'Swabian',\n",
              " 'mdf': 'Moksha',\n",
              " 'gil': 'Gilbertese',\n",
              " 'snd': 'Sindhi',\n",
              " 'tso': 'Tsonga',\n",
              " 'sot': 'Southern Sotho',\n",
              " 'zza': 'Zaza',\n",
              " 'tsn': 'Tswana',\n",
              " 'pau': 'Palauan',\n",
              " 'som': 'Somali',\n",
              " 'egl': 'Emilian',\n",
              " 'ady': 'Adyghe',\n",
              " 'asm': 'Assamese',\n",
              " 'ori': 'Oriya (macrolanguage)',\n",
              " 'dtp': 'Kadazan Dusun',\n",
              " 'cho': 'Choctaw',\n",
              " 'max': 'North Moluccan Malay',\n",
              " 'kam': 'Kamba (Kenya)',\n",
              " 'niu': 'Niuean',\n",
              " 'sag': 'Sango',\n",
              " 'ilo': 'Iloko',\n",
              " 'kaa': 'Kara-Kalpak',\n",
              " 'fuv': 'Nigerian Fulfulde',\n",
              " 'nch': 'Central Huasteca Nahuatl',\n",
              " 'hoc': 'Ho',\n",
              " 'iba': 'Iban',\n",
              " 'gbm': 'Garhwali',\n",
              " 'sun': 'Sundanese',\n",
              " 'war': 'Waray (Philippines)',\n",
              " 'mvv': 'Tagal Murut',\n",
              " 'pap': 'Papiamento',\n",
              " 'ary': 'Moroccan Arabic',\n",
              " 'kxi': 'Keningau Murut',\n",
              " 'csb': 'Kashubian',\n",
              " 'pag': 'Pangasinan',\n",
              " 'cos': 'Corsican',\n",
              " 'rif': 'Tarifit',\n",
              " 'kek': 'Kekchí',\n",
              " 'krc': 'Karachay-Balkar',\n",
              " 'aii': 'Assyrian Neo-Aramaic',\n",
              " 'ban': 'Balinese',\n",
              " 'ssw': 'Swati',\n",
              " 'tvl': 'Tuvalu',\n",
              " 'mfe': 'Morisyen',\n",
              " 'tah': 'Tahitian',\n",
              " 'bvy': 'Baybayanon',\n",
              " 'bcl': 'Central Bikol',\n",
              " 'hnj': 'Hmong Njua',\n",
              " 'nau': 'Nauru',\n",
              " 'nst': 'Tase Naga',\n",
              " 'afb': 'Gulf Arabic',\n",
              " 'quc': \"K'iche'\",\n",
              " 'min': 'Minangkabau',\n",
              " 'tmw': 'Temuan',\n",
              " 'mad': 'Madurese',\n",
              " 'bjn': 'Banjar',\n",
              " 'mai': 'Maithili',\n",
              " 'cjy': 'Jinyu Chinese',\n",
              " 'got': 'Gothic',\n",
              " 'hsn': 'Xiang Chinese',\n",
              " 'gan': 'Gan Chinese',\n",
              " 'tzl': 'Talossan',\n",
              " 'dws': 'Dutton World Speedwords',\n",
              " 'ldn': 'Láadan',\n",
              " 'afh': 'Afrihili',\n",
              " 'sgs': 'Samogitian',\n",
              " 'krl': 'Karelian',\n",
              " 'vep': 'Veps',\n",
              " 'rue': 'Rusyn',\n",
              " 'tly': 'Talysh',\n",
              " 'mic': \"Mi'kmaq\",\n",
              " 'ext': 'Extremaduran',\n",
              " 'izh': 'Ingrian',\n",
              " 'sma': 'Southern Sami',\n",
              " 'jam': 'Jamaican Creole English',\n",
              " 'cmo': 'Central Mnong',\n",
              " 'mwl': 'Mirandese',\n",
              " 'kpv': 'Komi-Zyrian',\n",
              " 'koi': 'Komi-Permyak',\n",
              " 'bis': 'Bislama',\n",
              " 'ike': 'Eastern Canadian Inuktitut',\n",
              " 'run': 'Rundi',\n",
              " 'evn': 'Evenki',\n",
              " 'ryu': 'Central Okinawan',\n",
              " 'mnc': 'Manchu',\n",
              " 'aoz': 'Uab Meto',\n",
              " 'otk': 'Old Turkish',\n",
              " 'kas': 'Kashmiri',\n",
              " 'aln': 'Gheg Albanian',\n",
              " 'akl': 'Aklanon',\n",
              " 'yua': 'Yucateco',\n",
              " 'shy': 'Tachawit',\n",
              " 'fkv': 'Kven Finnish',\n",
              " 'gos': 'Gronings',\n",
              " 'fij': 'Fijian',\n",
              " 'thv': 'Tahaggart Tamahaq',\n",
              " 'zgh': 'Standard Moroccan Tamazight',\n",
              " 'gcf': 'Guadeloupean Creole French',\n",
              " 'cay': 'Cayuga',\n",
              " 'xmf': 'Mingrelian',\n",
              " 'tig': 'Tigre',\n",
              " 'div': 'Dhivehi',\n",
              " 'lij': 'Ligurian',\n",
              " 'rap': 'Rapanui',\n",
              " 'hrx': 'Hunsrik',\n",
              " 'cpi': 'Chinese Pidgin English',\n",
              " 'tts': 'Northeastern Thai',\n",
              " 'gaa': 'Ga',\n",
              " 'tmr': 'Jewish Babylonian Aramaic (ca. 200-1200 CE)',\n",
              " 'iii': 'Sichuan Yi',\n",
              " 'ltg': 'Latgalian',\n",
              " 'bzt': 'Brithenig',\n",
              " 'syc': 'Classical Syriac',\n",
              " 'emx': 'Erromintxela',\n",
              " 'gom': 'Goan Konkani',\n",
              " 'chg': 'Chagatai',\n",
              " 'osp': 'Old Spanish',\n",
              " 'stq': 'Saterfriesisch',\n",
              " 'frr': 'Northern Frisian',\n",
              " 'fro': 'Old French (842-ca. 1400)',\n",
              " 'nys': 'Nyunga',\n",
              " 'toi': 'Tonga (Zambia)',\n",
              " 'new': 'Newari',\n",
              " 'phn': 'Phoenician',\n",
              " 'jpa': 'Jewish Palestinian Aramaic',\n",
              " 'rel': 'Rendille',\n",
              " 'drt': 'Drents',\n",
              " 'chn': 'Chinook jargon',\n",
              " 'pli': 'Pali',\n",
              " 'laa': 'Southern Subanen',\n",
              " 'bal': 'Baluchi',\n",
              " 'hdn': 'Northern Haida',\n",
              " 'hax': 'Southern Haida',\n",
              " 'mik': 'Mikasuki',\n",
              " 'ajp': 'South Levantine Arabic',\n",
              " 'xqa': 'Karakhanid',\n",
              " 'pal': 'Pahlavi',\n",
              " 'crk': 'Plains Cree',\n",
              " 'mni': 'Manipuri',\n",
              " 'lut': 'Lushootseed',\n",
              " 'ayl': 'Libyan Arabic',\n",
              " 'ood': \"Tohono O'odham\",\n",
              " 'sdh': 'Southern Kurdish',\n",
              " 'ofs': 'Old Frisian',\n",
              " 'nus': 'Nuer',\n",
              " 'kiu': 'Kirmanjki (individual language)',\n",
              " 'diq': 'Dimli (individual language)',\n",
              " 'qxq': \"Qashqa'i\",\n",
              " 'alt': 'Southern Altai',\n",
              " 'bfz': 'Mahasu Pahari',\n",
              " 'klj': 'Turkic Khalaj',\n",
              " 'mus': 'Creek',\n",
              " 'srn': 'Sranan Tongo',\n",
              " 'guc': 'Wayuu',\n",
              " 'lim': 'Limburgan',\n",
              " 'zea': 'Zeeuws',\n",
              " 'shi': 'Tachelhit',\n",
              " 'mnr': 'Mono (USA)',\n",
              " 'bom': 'Berom',\n",
              " 'sat': 'Santali',\n",
              " 'szl': 'Silesian',\n",
              " 'igs': 'Interglossa'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msJ4s8Z_NCTL",
        "outputId": "b326111c-8d02-4f92-ad85-d773a1c3b1cf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l2l = {}"
      ],
      "metadata": {
        "id": "omnXVLuONgFa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l2l[\"country\"] = data"
      ],
      "metadata": {
        "id": "yx34Wz8kNihZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l2l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BEcCYw7NrEa",
        "outputId": "00ceddd8-4d79-4cd6-e763-ec3b69165102"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'country': {'cmn': 'Mandarin Chinese',\n",
              "  'deu': 'German',\n",
              "  'rus': 'Russian',\n",
              "  'fra': 'French',\n",
              "  'eng': 'English',\n",
              "  'jpn': 'Japanese',\n",
              "  'spa': 'Spanish',\n",
              "  'ita': 'Italian',\n",
              "  'kor': 'Korean',\n",
              "  'vie': 'Vietnamese',\n",
              "  'nld': 'Dutch',\n",
              "  'epo': 'Esperanto',\n",
              "  'por': 'Portuguese',\n",
              "  'tur': 'Turkish',\n",
              "  'heb': 'Hebrew',\n",
              "  'hun': 'Hungarian',\n",
              "  'ell': 'Modern Greek (1453-)',\n",
              "  'ind': 'Indonesian',\n",
              "  'ara': 'Arabic',\n",
              "  'arz': 'Egyptian Arabic',\n",
              "  'fin': 'Finnish',\n",
              "  'bul': 'Bulgarian',\n",
              "  'yue': 'Yue Chinese',\n",
              "  'swe': 'Swedish',\n",
              "  'ukr': 'Ukrainian',\n",
              "  'bel': 'Belarusian',\n",
              "  'que': 'Quechua',\n",
              "  'ces': 'Czech',\n",
              "  'swh': 'Swahili (individual language)',\n",
              "  'nno': 'Norwegian Nynorsk',\n",
              "  'wuu': 'Wu Chinese',\n",
              "  'nob': 'Norwegian Bokmål',\n",
              "  'zsm': 'Standard Malay',\n",
              "  'est': 'Estonian',\n",
              "  'kat': 'Georgian',\n",
              "  'pol': 'Polish',\n",
              "  'lat': 'Latin',\n",
              "  'urd': 'Urdu',\n",
              "  'sqi': 'Albanian',\n",
              "  'isl': 'Icelandic',\n",
              "  'fry': 'Western Frisian',\n",
              "  'afr': 'Afrikaans',\n",
              "  'ron': 'Romanian',\n",
              "  'fao': 'Faroese',\n",
              "  'san': 'Sanskrit',\n",
              "  'bre': 'Breton',\n",
              "  'tat': 'Tatar',\n",
              "  'yid': 'Yiddish',\n",
              "  'uig': 'Uighur',\n",
              "  'uzb': 'Uzbek',\n",
              "  'srp': 'Serbian',\n",
              "  'qya': 'Quenya',\n",
              "  'dan': 'Danish',\n",
              "  'pes': 'Iranian Persian',\n",
              "  'slk': 'Slovak',\n",
              "  'eus': 'Basque',\n",
              "  'cycl': 'CycL',\n",
              "  'acm': 'Mesopotamian Arabic',\n",
              "  'tgl': 'Tagalog',\n",
              "  'lvs': 'Standard Latvian',\n",
              "  'kaz': 'Kazakh',\n",
              "  'hye': 'Armenian',\n",
              "  'hin': 'Hindi',\n",
              "  'lit': 'Lithuanian',\n",
              "  'ben': 'Bengali',\n",
              "  'cat': 'Catalan',\n",
              "  'bos': 'Bosnian',\n",
              "  'hrv': 'Croatian',\n",
              "  'tha': 'Thai',\n",
              "  'orv': 'Old Russian',\n",
              "  'cha': 'Chamorro',\n",
              "  'mon': 'Mongolian',\n",
              "  'lzh': 'Literary Chinese',\n",
              "  'scn': 'Sicilian',\n",
              "  'gle': 'Irish',\n",
              "  'mkd': 'Macedonian',\n",
              "  'slv': 'Slovenian',\n",
              "  'frm': 'Middle French (ca. 1400-1600)',\n",
              "  'glg': 'Galician',\n",
              "  'vol': 'Volapük',\n",
              "  'ain': 'Ainu (Japan)',\n",
              "  'jbo': 'Lojban',\n",
              "  'tok': 'Toki Pona',\n",
              "  'ina': 'Interlingua (International Auxiliary Language Association)',\n",
              "  'nds': 'Low German',\n",
              "  'mal': 'Malayalam',\n",
              "  'tlh': 'Klingon',\n",
              "  'roh': 'Romansh',\n",
              "  'ltz': 'Luxembourgish',\n",
              "  'oss': 'Ossetian',\n",
              "  'ido': 'Ido',\n",
              "  'gla': 'Scottish Gaelic',\n",
              "  'mlt': 'Maltese',\n",
              "  'sco': 'Scots',\n",
              "  'ast': 'Asturian',\n",
              "  'jav': 'Javanese',\n",
              "  'oci': 'Occitan (post 1500)',\n",
              "  'ile': 'Interlingue',\n",
              "  'ota': 'Ottoman Turkish (1500-1928)',\n",
              "  'xal': 'Kalmyk',\n",
              "  'tel': 'Telugu',\n",
              "  'sjn': 'Sindarin',\n",
              "  'nov': 'Novial',\n",
              "  'khm': 'Central Khmer',\n",
              "  'tpi': 'Tok Pisin',\n",
              "  'ang': 'Old English (ca. 450-1100)',\n",
              "  'aze': 'Azerbaijani',\n",
              "  'tgk': 'Tajik',\n",
              "  'tuk': 'Turkmen',\n",
              "  'chv': 'Chuvash',\n",
              "  'hsb': 'Upper Sorbian',\n",
              "  'dsb': 'Lower Sorbian',\n",
              "  'bod': 'Tibetan',\n",
              "  'sme': 'Northern Sami',\n",
              "  'cym': 'Welsh',\n",
              "  'mri': 'Maori',\n",
              "  'ksh': 'Kölsch',\n",
              "  'kmr': 'Northern Kurdish',\n",
              "  'ewe': 'Ewe',\n",
              "  'kab': 'Kabyle',\n",
              "  'ber': 'Berber languages',\n",
              "  'tpw': 'Tupí',\n",
              "  'udm': 'Udmurt',\n",
              "  'lld': 'Ladin',\n",
              "  'pms': 'Piemontese',\n",
              "  'lad': 'Ladino',\n",
              "  'grn': 'Guarani',\n",
              "  'mlg': 'Malagasy',\n",
              "  'xho': 'Xhosa',\n",
              "  'pnb': 'Western Panjabi',\n",
              "  'grc': 'Ancient Greek (to 1453)',\n",
              "  'hat': 'Haitian',\n",
              "  'lao': 'Lao',\n",
              "  'npi': 'Nepali (individual language)',\n",
              "  'cor': 'Cornish',\n",
              "  'nah': 'Nahuatl',\n",
              "  'avk': 'Kotava',\n",
              "  'mar': 'Marathi',\n",
              "  'guj': 'Gujarati',\n",
              "  'pan': 'Panjabi',\n",
              "  'kir': 'Kirghiz',\n",
              "  'myv': 'Erzya',\n",
              "  'prg': 'Prussian',\n",
              "  'sux': 'Sumerian',\n",
              "  'crs': 'Seselwa Creole French',\n",
              "  'ckt': 'Chukot',\n",
              "  'bak': 'Bashkir',\n",
              "  'zlm': 'Malay (individual language)',\n",
              "  'hil': 'Hiligaynon',\n",
              "  'cbk': 'Chavacano',\n",
              "  'chr': 'Cherokee',\n",
              "  'nav': 'Navajo',\n",
              "  'lkt': 'Lakota',\n",
              "  'enm': 'Middle English (1100-1500)',\n",
              "  'arq': 'Algerian Arabic',\n",
              "  'lin': 'Lingala',\n",
              "  'abk': 'Abkhazian',\n",
              "  'pcd': 'Picard',\n",
              "  'rom': 'Romany',\n",
              "  'gsw': 'Swiss German',\n",
              "  'tam': 'Tamil',\n",
              "  'zul': 'Zulu',\n",
              "  'awa': 'Awadhi',\n",
              "  'wln': 'Walloon',\n",
              "  'amh': 'Amharic',\n",
              "  'bar': 'Bavarian',\n",
              "  'hbo': 'Ancient Hebrew',\n",
              "  'mhr': 'Eastern Mari',\n",
              "  'bho': 'Bhojpuri',\n",
              "  'mrj': 'Western Mari',\n",
              "  'ckb': 'Central Kurdish',\n",
              "  'osx': 'Old Saxon',\n",
              "  'pfl': 'Pfaelzisch',\n",
              "  'mgm': 'Mambae',\n",
              "  'sna': 'Shona',\n",
              "  'mah': 'Marshallese',\n",
              "  'hau': 'Hausa',\n",
              "  'kan': 'Kannada',\n",
              "  'nog': 'Nogai',\n",
              "  'sin': 'Sinhala',\n",
              "  'glv': 'Manx',\n",
              "  'dng': 'Dungan',\n",
              "  'kal': 'Kalaallisut',\n",
              "  'liv': 'Liv',\n",
              "  'vro': 'Võro',\n",
              "  'apc': 'North Levantine Arabic',\n",
              "  'jdt': 'Judeo-Tat',\n",
              "  'fur': 'Friulian',\n",
              "  'che': 'Chechen',\n",
              "  'haw': 'Hawaiian',\n",
              "  'yor': 'Yoruba',\n",
              "  'crh': 'Crimean Tatar',\n",
              "  'pdc': 'Pennsylvania German',\n",
              "  'ppl': 'Pipil',\n",
              "  'kin': 'Kinyarwanda',\n",
              "  'shs': 'Shuswap',\n",
              "  'mnw': 'Mon',\n",
              "  'tet': 'Tetum',\n",
              "  'sah': 'Yakut',\n",
              "  'kum': 'Kumyk',\n",
              "  'ngt': 'Ngeq',\n",
              "  'nya': 'Nyanja',\n",
              "  'pus': 'Pushto',\n",
              "  'hif': 'Fiji Hindi',\n",
              "  'mya': 'Burmese',\n",
              "  'moh': 'Mohawk',\n",
              "  'wol': 'Wolof',\n",
              "  'tir': 'Tigrinya',\n",
              "  'ton': 'Tonga (Tonga Islands)',\n",
              "  'lzz': 'Laz',\n",
              "  'oar': 'Old Aramaic (up to 700 BCE)',\n",
              "  'lug': 'Ganda',\n",
              "  'brx': 'Bodo (India)',\n",
              "  'non': 'Old Norse',\n",
              "  'mww': 'Hmong Daw',\n",
              "  'hak': 'Hakka Chinese',\n",
              "  'nlv': 'Orizaba Nahuatl',\n",
              "  'ngu': 'Guerrero Nahuatl',\n",
              "  'bua': 'Buriat',\n",
              "  'aym': 'Aymara',\n",
              "  'vec': 'Venetian',\n",
              "  'ibo': 'Igbo',\n",
              "  'tkl': 'Tokelau',\n",
              "  'bam': 'Bambara',\n",
              "  'kha': 'Khasi',\n",
              "  'ceb': 'Cebuano',\n",
              "  'lou': 'Louisiana Creole',\n",
              "  'fuc': 'Pulaar',\n",
              "  'smo': 'Samoan',\n",
              "  'gag': 'Gagauz',\n",
              "  'lfn': 'Lingua Franca Nova',\n",
              "  'arg': 'Aragonese',\n",
              "  'umb': 'Umbundu',\n",
              "  'tyv': 'Tuvinian',\n",
              "  'kjh': 'Khakas',\n",
              "  'oji': 'Ojibwa',\n",
              "  'cyo': 'Cuyonon',\n",
              "  'urh': 'Urhobo',\n",
              "  'kzj': 'Coastal Kadazan',\n",
              "  'pam': 'Pampanga',\n",
              "  'srd': 'Sardinian',\n",
              "  'lmo': 'Lombard',\n",
              "  'swg': 'Swabian',\n",
              "  'mdf': 'Moksha',\n",
              "  'gil': 'Gilbertese',\n",
              "  'snd': 'Sindhi',\n",
              "  'tso': 'Tsonga',\n",
              "  'sot': 'Southern Sotho',\n",
              "  'zza': 'Zaza',\n",
              "  'tsn': 'Tswana',\n",
              "  'pau': 'Palauan',\n",
              "  'som': 'Somali',\n",
              "  'egl': 'Emilian',\n",
              "  'ady': 'Adyghe',\n",
              "  'asm': 'Assamese',\n",
              "  'ori': 'Oriya (macrolanguage)',\n",
              "  'dtp': 'Kadazan Dusun',\n",
              "  'cho': 'Choctaw',\n",
              "  'max': 'North Moluccan Malay',\n",
              "  'kam': 'Kamba (Kenya)',\n",
              "  'niu': 'Niuean',\n",
              "  'sag': 'Sango',\n",
              "  'ilo': 'Iloko',\n",
              "  'kaa': 'Kara-Kalpak',\n",
              "  'fuv': 'Nigerian Fulfulde',\n",
              "  'nch': 'Central Huasteca Nahuatl',\n",
              "  'hoc': 'Ho',\n",
              "  'iba': 'Iban',\n",
              "  'gbm': 'Garhwali',\n",
              "  'sun': 'Sundanese',\n",
              "  'war': 'Waray (Philippines)',\n",
              "  'mvv': 'Tagal Murut',\n",
              "  'pap': 'Papiamento',\n",
              "  'ary': 'Moroccan Arabic',\n",
              "  'kxi': 'Keningau Murut',\n",
              "  'csb': 'Kashubian',\n",
              "  'pag': 'Pangasinan',\n",
              "  'cos': 'Corsican',\n",
              "  'rif': 'Tarifit',\n",
              "  'kek': 'Kekchí',\n",
              "  'krc': 'Karachay-Balkar',\n",
              "  'aii': 'Assyrian Neo-Aramaic',\n",
              "  'ban': 'Balinese',\n",
              "  'ssw': 'Swati',\n",
              "  'tvl': 'Tuvalu',\n",
              "  'mfe': 'Morisyen',\n",
              "  'tah': 'Tahitian',\n",
              "  'bvy': 'Baybayanon',\n",
              "  'bcl': 'Central Bikol',\n",
              "  'hnj': 'Hmong Njua',\n",
              "  'nau': 'Nauru',\n",
              "  'nst': 'Tase Naga',\n",
              "  'afb': 'Gulf Arabic',\n",
              "  'quc': \"K'iche'\",\n",
              "  'min': 'Minangkabau',\n",
              "  'tmw': 'Temuan',\n",
              "  'mad': 'Madurese',\n",
              "  'bjn': 'Banjar',\n",
              "  'mai': 'Maithili',\n",
              "  'cjy': 'Jinyu Chinese',\n",
              "  'got': 'Gothic',\n",
              "  'hsn': 'Xiang Chinese',\n",
              "  'gan': 'Gan Chinese',\n",
              "  'tzl': 'Talossan',\n",
              "  'dws': 'Dutton World Speedwords',\n",
              "  'ldn': 'Láadan',\n",
              "  'afh': 'Afrihili',\n",
              "  'sgs': 'Samogitian',\n",
              "  'krl': 'Karelian',\n",
              "  'vep': 'Veps',\n",
              "  'rue': 'Rusyn',\n",
              "  'tly': 'Talysh',\n",
              "  'mic': \"Mi'kmaq\",\n",
              "  'ext': 'Extremaduran',\n",
              "  'izh': 'Ingrian',\n",
              "  'sma': 'Southern Sami',\n",
              "  'jam': 'Jamaican Creole English',\n",
              "  'cmo': 'Central Mnong',\n",
              "  'mwl': 'Mirandese',\n",
              "  'kpv': 'Komi-Zyrian',\n",
              "  'koi': 'Komi-Permyak',\n",
              "  'bis': 'Bislama',\n",
              "  'ike': 'Eastern Canadian Inuktitut',\n",
              "  'run': 'Rundi',\n",
              "  'evn': 'Evenki',\n",
              "  'ryu': 'Central Okinawan',\n",
              "  'mnc': 'Manchu',\n",
              "  'aoz': 'Uab Meto',\n",
              "  'otk': 'Old Turkish',\n",
              "  'kas': 'Kashmiri',\n",
              "  'aln': 'Gheg Albanian',\n",
              "  'akl': 'Aklanon',\n",
              "  'yua': 'Yucateco',\n",
              "  'shy': 'Tachawit',\n",
              "  'fkv': 'Kven Finnish',\n",
              "  'gos': 'Gronings',\n",
              "  'fij': 'Fijian',\n",
              "  'thv': 'Tahaggart Tamahaq',\n",
              "  'zgh': 'Standard Moroccan Tamazight',\n",
              "  'gcf': 'Guadeloupean Creole French',\n",
              "  'cay': 'Cayuga',\n",
              "  'xmf': 'Mingrelian',\n",
              "  'tig': 'Tigre',\n",
              "  'div': 'Dhivehi',\n",
              "  'lij': 'Ligurian',\n",
              "  'rap': 'Rapanui',\n",
              "  'hrx': 'Hunsrik',\n",
              "  'cpi': 'Chinese Pidgin English',\n",
              "  'tts': 'Northeastern Thai',\n",
              "  'gaa': 'Ga',\n",
              "  'tmr': 'Jewish Babylonian Aramaic (ca. 200-1200 CE)',\n",
              "  'iii': 'Sichuan Yi',\n",
              "  'ltg': 'Latgalian',\n",
              "  'bzt': 'Brithenig',\n",
              "  'syc': 'Classical Syriac',\n",
              "  'emx': 'Erromintxela',\n",
              "  'gom': 'Goan Konkani',\n",
              "  'chg': 'Chagatai',\n",
              "  'osp': 'Old Spanish',\n",
              "  'stq': 'Saterfriesisch',\n",
              "  'frr': 'Northern Frisian',\n",
              "  'fro': 'Old French (842-ca. 1400)',\n",
              "  'nys': 'Nyunga',\n",
              "  'toi': 'Tonga (Zambia)',\n",
              "  'new': 'Newari',\n",
              "  'phn': 'Phoenician',\n",
              "  'jpa': 'Jewish Palestinian Aramaic',\n",
              "  'rel': 'Rendille',\n",
              "  'drt': 'Drents',\n",
              "  'chn': 'Chinook jargon',\n",
              "  'pli': 'Pali',\n",
              "  'laa': 'Southern Subanen',\n",
              "  'bal': 'Baluchi',\n",
              "  'hdn': 'Northern Haida',\n",
              "  'hax': 'Southern Haida',\n",
              "  'mik': 'Mikasuki',\n",
              "  'ajp': 'South Levantine Arabic',\n",
              "  'xqa': 'Karakhanid',\n",
              "  'pal': 'Pahlavi',\n",
              "  'crk': 'Plains Cree',\n",
              "  'mni': 'Manipuri',\n",
              "  'lut': 'Lushootseed',\n",
              "  'ayl': 'Libyan Arabic',\n",
              "  'ood': \"Tohono O'odham\",\n",
              "  'sdh': 'Southern Kurdish',\n",
              "  'ofs': 'Old Frisian',\n",
              "  'nus': 'Nuer',\n",
              "  'kiu': 'Kirmanjki (individual language)',\n",
              "  'diq': 'Dimli (individual language)',\n",
              "  'qxq': \"Qashqa'i\",\n",
              "  'alt': 'Southern Altai',\n",
              "  'bfz': 'Mahasu Pahari',\n",
              "  'klj': 'Turkic Khalaj',\n",
              "  'mus': 'Creek',\n",
              "  'srn': 'Sranan Tongo',\n",
              "  'guc': 'Wayuu',\n",
              "  'lim': 'Limburgan',\n",
              "  'zea': 'Zeeuws',\n",
              "  'shi': 'Tachelhit',\n",
              "  'mnr': 'Mono (USA)',\n",
              "  'bom': 'Berom',\n",
              "  'sat': 'Santali',\n",
              "  'szl': 'Silesian',\n",
              "  'igs': 'Interglossa'}}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_l2l = pd.DataFrame(l2l)"
      ],
      "metadata": {
        "id": "cDOa7mhfN1jK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_l2l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "-9B_NY47OGRk",
        "outputId": "18888082-5bdb-4198-8809-175d13aa7a72"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         country\n",
              "abk                    Abkhazian\n",
              "acm          Mesopotamian Arabic\n",
              "ady                       Adyghe\n",
              "afb                  Gulf Arabic\n",
              "afh                     Afrihili\n",
              "..                           ...\n",
              "zgh  Standard Moroccan Tamazight\n",
              "zlm  Malay (individual language)\n",
              "zsm               Standard Malay\n",
              "zul                         Zulu\n",
              "zza                         Zaza\n",
              "\n",
              "[404 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6bbec60d-7d0a-4f2b-8753-cc590185b59d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>abk</th>\n",
              "      <td>Abkhazian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>acm</th>\n",
              "      <td>Mesopotamian Arabic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ady</th>\n",
              "      <td>Adyghe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>afb</th>\n",
              "      <td>Gulf Arabic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>afh</th>\n",
              "      <td>Afrihili</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zgh</th>\n",
              "      <td>Standard Moroccan Tamazight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zlm</th>\n",
              "      <td>Malay (individual language)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zsm</th>\n",
              "      <td>Standard Malay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zul</th>\n",
              "      <td>Zulu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zza</th>\n",
              "      <td>Zaza</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>404 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6bbec60d-7d0a-4f2b-8753-cc590185b59d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6bbec60d-7d0a-4f2b-8753-cc590185b59d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6bbec60d-7d0a-4f2b-8753-cc590185b59d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_sen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "whUdbXrDOo-I",
        "outputId": "7f7e5ad7-6035-47a4-baa3-80d065c927ba"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                id lan_code                      sentence\n",
              "0                1      cmn                        我們試試看！\n",
              "1                2      cmn                       我该去睡觉了。\n",
              "2                3      cmn                       你在干什麼啊？\n",
              "3                4      cmn                        這是什麼啊？\n",
              "4                5      cmn        今天是６月１８号，也是Muiriel的生日！\n",
              "...            ...      ...                           ...\n",
              "10341807  10794524      spa  Quiero este libro por favor.\n",
              "10341808  10794525      spa           Los han hecho huir.\n",
              "10341809  10794526      spa                  Los botaron.\n",
              "10341810  10794527      spa          Los hicieron correr.\n",
              "10341811  10794528      spa                Los corrieron.\n",
              "\n",
              "[10341812 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3411939-8356-4e41-a22f-c2614b57fa39\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>lan_code</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>cmn</td>\n",
              "      <td>我們試試看！</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>cmn</td>\n",
              "      <td>我该去睡觉了。</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>cmn</td>\n",
              "      <td>你在干什麼啊？</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>cmn</td>\n",
              "      <td>這是什麼啊？</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>cmn</td>\n",
              "      <td>今天是６月１８号，也是Muiriel的生日！</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10341807</th>\n",
              "      <td>10794524</td>\n",
              "      <td>spa</td>\n",
              "      <td>Quiero este libro por favor.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10341808</th>\n",
              "      <td>10794525</td>\n",
              "      <td>spa</td>\n",
              "      <td>Los han hecho huir.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10341809</th>\n",
              "      <td>10794526</td>\n",
              "      <td>spa</td>\n",
              "      <td>Los botaron.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10341810</th>\n",
              "      <td>10794527</td>\n",
              "      <td>spa</td>\n",
              "      <td>Los hicieron correr.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10341811</th>\n",
              "      <td>10794528</td>\n",
              "      <td>spa</td>\n",
              "      <td>Los corrieron.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10341812 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3411939-8356-4e41-a22f-c2614b57fa39')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d3411939-8356-4e41-a22f-c2614b57fa39 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d3411939-8356-4e41-a22f-c2614b57fa39');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "phrase = '我們試試看!'\n",
        "ts.google(phrase, from_language='zh-CN', to_language='th')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KtL40lzNQu8Y",
        "outputId": "5bfe6b82-cf32-4dbb-eeeb-0a59a4a2dd89"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'มาลองดูกัน!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_sen[\"lan_code\"].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6x83Ug1cRb77",
        "outputId": "75e563d7-2a36-47b7-da6c-7aacb2e1f926"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['cmn', 'deu', 'rus', 'fra', 'eng', 'jpn', 'spa', 'ita', 'kor',\n",
              "       'vie', 'nld', 'epo', 'por', 'tur', 'heb', 'hun', 'ell', 'ind',\n",
              "       'ara', 'arz', 'fin', 'bul', 'yue', 'swe', 'ukr', 'bel', 'que',\n",
              "       'ces', 'swh', 'nno', 'wuu', 'nob', 'zsm', 'est', 'kat', 'pol',\n",
              "       'lat', 'urd', 'sqi', 'isl', 'fry', 'afr', 'ron', 'fao', 'san',\n",
              "       'bre', 'tat', 'yid', 'uig', 'uzb', 'srp', 'qya', 'dan', 'pes',\n",
              "       'slk', 'eus', 'cycl', 'acm', 'tgl', 'lvs', 'kaz', 'hye', 'hin',\n",
              "       'lit', 'ben', 'cat', 'bos', 'hrv', 'tha', 'orv', 'cha', 'mon',\n",
              "       'lzh', 'scn', 'gle', 'mkd', 'slv', 'frm', 'glg', 'vol', 'ain',\n",
              "       'jbo', 'tok', 'ina', 'nds', 'mal', 'tlh', 'roh', 'ltz', 'oss',\n",
              "       'ido', 'gla', 'mlt', 'sco', 'ast', 'jav', 'oci', 'ile', 'ota',\n",
              "       'xal', 'tel', 'sjn', 'nov', 'khm', 'tpi', 'ang', 'aze', 'tgk',\n",
              "       'tuk', 'chv', 'hsb', 'dsb', 'bod', 'sme', 'cym', 'mri', 'ksh',\n",
              "       'kmr', 'ewe', 'kab', 'ber', 'tpw', 'udm', 'lld', 'pms', 'lad',\n",
              "       'grn', 'mlg', 'xho', 'pnb', 'grc', 'hat', 'lao', 'npi', 'cor',\n",
              "       'nah', 'avk', 'mar', 'guj', 'pan', 'kir', 'myv', 'prg', 'sux',\n",
              "       'crs', 'ckt', 'bak', 'zlm', 'hil', 'cbk', 'chr', 'nav', 'lkt',\n",
              "       'enm', 'arq', 'lin', 'abk', 'pcd', 'rom', 'gsw', 'tam', 'zul',\n",
              "       'awa', 'wln', 'amh', 'bar', 'hbo', 'mhr', 'bho', 'mrj', 'ckb',\n",
              "       'osx', 'pfl', 'mgm', 'sna', 'mah', 'hau', 'kan', 'nog', 'sin',\n",
              "       'glv', 'dng', 'kal', 'liv', 'vro', 'apc', 'jdt', 'fur', 'che',\n",
              "       'haw', 'yor', 'crh', 'pdc', 'ppl', 'kin', 'shs', 'mnw', 'tet',\n",
              "       'sah', 'kum', 'ngt', 'nya', 'pus', 'hif', 'mya', 'moh', 'wol',\n",
              "       'tir', 'ton', 'lzz', 'oar', 'lug', 'brx', 'non', 'mww', 'hak',\n",
              "       'nlv', 'ngu', 'bua', 'aym', 'vec', 'ibo', 'tkl', 'bam', 'kha',\n",
              "       'ceb', 'lou', 'fuc', 'smo', 'gag', 'lfn', 'arg', 'umb', 'tyv',\n",
              "       'kjh', 'oji', 'cyo', 'urh', 'kzj', 'pam', 'srd', 'lmo', 'swg',\n",
              "       'mdf', 'gil', 'snd', 'tso', 'sot', 'zza', 'tsn', 'pau', 'som',\n",
              "       'egl', 'ady', 'asm', 'ori', 'dtp', 'cho', 'max', 'kam', 'niu',\n",
              "       'sag', 'ilo', 'kaa', 'fuv', 'nch', 'hoc', 'iba', 'gbm', 'sun',\n",
              "       'war', 'mvv', 'pap', 'ary', 'kxi', 'csb', 'pag', 'cos', 'rif',\n",
              "       'kek', 'krc', 'aii', 'ban', 'ssw', 'tvl', 'mfe', 'tah', 'bvy',\n",
              "       'bcl', 'hnj', 'nau', 'nst', 'afb', 'quc', 'min', 'tmw', 'mad',\n",
              "       'bjn', 'mai', 'cjy', 'got', 'hsn', 'gan', 'tzl', 'dws', 'ldn',\n",
              "       'afh', 'sgs', 'krl', 'vep', 'rue', 'tly', 'mic', 'ext', 'izh',\n",
              "       'sma', 'jam', 'cmo', 'mwl', 'kpv', 'koi', 'bis', 'ike', 'run',\n",
              "       'evn', 'ryu', 'mnc', 'aoz', 'otk', 'kas', 'aln', 'akl', 'yua',\n",
              "       'shy', 'fkv', 'gos', 'fij', 'thv', 'zgh', 'gcf', 'cay', 'xmf',\n",
              "       'tig', 'div', 'lij', 'rap', 'hrx', 'cpi', 'tts', 'gaa', 'tmr',\n",
              "       'iii', 'ltg', 'bzt', 'syc', 'emx', 'gom', 'chg', 'osp', 'stq',\n",
              "       'frr', 'fro', 'nys', 'toi', 'new', 'phn', 'jpa', 'rel', 'drt',\n",
              "       'chn', 'pli', 'laa', 'bal', 'hdn', 'hax', 'mik', 'ajp', 'xqa',\n",
              "       'pal', 'crk', 'mni', 'lut', 'ayl', 'ood', 'sdh', 'ofs', 'nus',\n",
              "       'kiu', 'diq', 'qxq', 'alt', 'bfz', 'klj', 'mus', 'srn', 'guc',\n",
              "       'lim', 'zea', 'shi', 'mnr', 'bom', 'sat', 'szl', 'igs'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update                                                                          # อัพเดท Package ทั้งหมดใน VM ตัวนี้\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null                                  # ติดตั้ง Java Development Kit (จำเป็นสำหรับการติดตั้ง Spark)\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz # ติดตั้ง Spark 3.1.2\n",
        "!tar xzvf spark-3.1.2-bin-hadoop2.7.tgz                                                  # Unzip ไฟล์ Spark 3.1.2\n",
        "!pip install -q findspark==1.3.0                                                         # ติดตั้ง Package Python สำหรับเชื่อมต่อกับ Spark "
      ],
      "metadata": {
        "id": "OtQ6TGNySa6n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc5f06f2-20e8-4468-c928-e273e321e227"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [Waiting for headers] [Connected to cloud.r-project.org (108.157.162.110)] [\r                                                                               \rHit:2 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "\r0% [Waiting for headers] [Connected to cloud.r-project.org (108.157.162.110)] [\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connected to cloud.r-projec\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Waiting for headers] [Conne\r                                                                               \rHit:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Waiting for headers] [Conne\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "spark-3.1.2-bin-hadoop2.7/\n",
            "spark-3.1.2-bin-hadoop2.7/R/\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/sparkr.zip\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/worker/\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/worker/worker.R\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/worker/daemon.R\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/tests/\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/tests/testthat/\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/tests/testthat/test_basic.R\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/profile/\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/profile/shell.R\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/profile/general.R\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/R/\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/R/SparkR\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdx\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdb\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/Meta/\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/Meta/features.rds\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/Meta/package.rds\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/Meta/links.rds\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/Meta/hsearch.rds\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/Meta/nsInfo.rds\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/Meta/Rd.rds\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/DESCRIPTION\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/NAMESPACE\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/INDEX\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/html/\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/html/R.css\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/html/00Index.html\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/help/\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/help/aliases.rds\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/help/AnIndex\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdx\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdb\n",
            "spark-3.1.2-bin-hadoop2.7/R/lib/SparkR/help/paths.rds\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/workers.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/stop-workers.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/stop-worker.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/stop-thriftserver.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/stop-slaves.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/stop-slave.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/stop-mesos-shuffle-service.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/stop-mesos-dispatcher.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/stop-master.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/stop-history-server.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/stop-all.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/start-workers.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/start-worker.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/start-thriftserver.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/start-slaves.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/start-slave.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/start-mesos-shuffle-service.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/start-mesos-dispatcher.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/start-master.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/start-history-server.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/start-all.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/spark-daemons.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/spark-daemon.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/slaves.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/decommission-worker.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/decommission-slave.sh\n",
            "spark-3.1.2-bin-hadoop2.7/sbin/spark-config.sh\n",
            "spark-3.1.2-bin-hadoop2.7/examples/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/jars/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/jars/spark-examples_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/examples/jars/scopt_2.12-3.7.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/users.parquet\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/users.orc\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/users.avro\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/user.avsc\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/people.txt\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/people.json\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/people.csv\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/kv1.txt\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/full_user.avsc\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/employees.json\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/dir1/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/dir1/file3.json\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/dir1/file1.parquet\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/dir1/dir2/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/resources/dir1/dir2/file2.parquet\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/streaming/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/streaming/structured_network_wordcount.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/svmLinear.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/survreg.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/randomForest.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/prefixSpan.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/powerIterationClustering.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/naiveBayes.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/mlp.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/ml.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/logit.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/lm_with_elastic_net.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/lda.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/kstest.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/kmeans.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/isoreg.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/glm.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/gbt.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/gaussianMixture.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/fpm.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/fmRegressor.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/fmClassifier.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/decisionTree.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/bisectingKmeans.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/ml/als.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/dataframe.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/data-manipulation.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/r/RSparkSQLExample.R\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/wordcount.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/transitive_closure.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/streaming/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/streaming/stateful_network_wordcount.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/streaming/sql_network_wordcount.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/streaming/recoverable_network_wordcount.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/streaming/queue_stream.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/streaming/network_wordjoinsentiments.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/streaming/network_wordcount.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/streaming/hdfs_wordcount.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/status_api_demo.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/sql/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/sql/streaming/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/sql/hive.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/sql/basic.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/sql/arrow.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/sql/datasource.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/sort.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/pi.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/parquet_inputformat.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/pagerank.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/word2vec_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/word2vec.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/tf_idf_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/svm_with_sgd_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/svd_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/summary_statistics_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/streaming_k_means_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/stratified_sampling_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/standard_scaler_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/sampled_rdds.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/regression_metrics_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/recommendation_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/ranking_metrics_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/random_rdd_generation.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_regression_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_classification_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/power_iteration_clustering_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/pca_rowmatrix_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/normalizer_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/naive_bayes_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/multi_label_metrics_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/multi_class_metrics_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/kmeans.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/kernel_density_estimation_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/k_means_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/isotonic_regression_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_model.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/fpgrowth_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/elementwise_product_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_regression_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_classification_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/correlations_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/correlations.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/bisecting_k_means_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/mllib/binary_classification_metrics_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/word2vec_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/vector_slicer_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/vector_size_hint_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/vector_indexer_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/vector_assembler_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/variance_threshold_selector_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/univariate_feature_selector_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/train_validation_split.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/tokenizer_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/tf_idf_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/summarizer_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/string_indexer_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/stopwords_remover_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/standard_scaler_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/sql_transformer.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/robust_scaler_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/rformula_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/random_forest_regressor_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/random_forest_classifier_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/quantile_discretizer_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/prefixspan_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/power_iteration_clustering_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/polynomial_expansion_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/pipeline_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/pca_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/onehot_encoder_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/one_vs_rest_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/normalizer_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/naive_bayes_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/n_gram_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/multilayer_perceptron_classification.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/min_max_scaler_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/min_hash_lsh_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/max_abs_scaler_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_summary_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/linearsvc.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/lda_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/kmeans_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/isotonic_regression_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/interaction_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/index_to_string_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/imputer_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/generalized_linear_regression_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/gaussian_mixture_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/fpgrowth_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/fm_regressor_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/fm_classifier_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/feature_hasher_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/estimator_transformer_param_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/elementwise_product_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_regression_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_classification_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/dct_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/dataframe_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/cross_validator.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/count_vectorizer_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/correlation_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/chisq_selector_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/chi_square_test_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/bucketizer_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/bisecting_k_means_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/binarizer_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/als_example.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/ml/aft_survival_regression.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/logistic_regression.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/kmeans.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/avro_inputformat.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/python/als.py\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scripts/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/scripts/getGpusResources.sh\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n",
            "spark-3.1.2-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/tests/\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/tests/worker_memory_check.py\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/tests/python_executable_check.py\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/tests/pyfiles.py\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/tests/py_container_checks.py\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/tests/decommissioning_cleanup.py\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/tests/decommissioning.py\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/tests/autoscale.py\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/dockerfiles/\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/dockerfiles/spark/\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/dockerfiles/spark/entrypoint.sh\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/dockerfiles/spark/decom.sh\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/python/\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/R/\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n",
            "spark-3.1.2-bin-hadoop2.7/kubernetes/dockerfiles/spark/Dockerfile\n",
            "spark-3.1.2-bin-hadoop2.7/yarn/\n",
            "spark-3.1.2-bin-hadoop2.7/yarn/spark-3.1.2-yarn-shuffle.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/\n",
            "spark-3.1.2-bin-hadoop2.7/jars/zstd-jni-1.4.8-1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/zookeeper-3.4.14.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/zjsonpatch-0.3.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/xz-1.5.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/xmlenc-0.52.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/xml-apis-1.4.01.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/xercesImpl-2.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/xbean-asm7-shaded-4.15.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/velocity-1.5.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/univocity-parsers-2.9.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/transaction-api-1.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/threeten-extra-1.5.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/super-csv-2.2.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/stream-2.9.6.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/stax-api-1.0.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/stax-api-1.0-2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spire_2.12-0.17.0-M1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spire-util_2.12-0.17.0-M1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spire-platform_2.12-0.17.0-M1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spire-macros_2.12-0.17.0-M1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-yarn_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-unsafe_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-tags_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-tags_2.12-3.1.2-tests.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-streaming_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-sql_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-sketch_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-repl_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-network-shuffle_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-network-common_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-mllib_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-mllib-local_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-mesos_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-launcher_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-kvstore_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-kubernetes_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-hive_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-hive-thriftserver_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-graphx_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-core_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/spark-catalyst_2.12-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/snappy-java-1.1.8.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/snakeyaml-1.24.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/slf4j-log4j12-1.7.30.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/slf4j-api-1.7.30.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/shims-0.9.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/shapeless_2.12-2.3.3.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/scala-xml_2.12-1.2.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/scala-reflect-2.12.10.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/scala-parser-combinators_2.12-1.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/scala-library-2.12.10.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/scala-compiler-2.12.10.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/scala-collection-compat_2.12-2.1.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/pyrolite-4.30.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/py4j-0.10.9.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/protobuf-java-2.5.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/parquet-jackson-1.10.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/parquet-hadoop-1.10.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/parquet-format-2.4.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/parquet-encoding-1.10.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/parquet-common-1.10.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/parquet-column-1.10.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/paranamer-2.8.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/osgi-resource-locator-1.0.3.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/oro-2.0.8.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/orc-shims-1.5.12.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/orc-mapreduce-1.5.12.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/orc-core-1.5.12.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/opencsv-2.3.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/okio-1.14.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/okhttp-3.12.12.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/objenesis-2.6.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/netty-all-4.1.51.Final.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/minlog-1.3.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/metrics-jvm-4.1.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/metrics-json-4.1.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/metrics-jmx-4.1.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/metrics-graphite-4.1.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/metrics-core-4.1.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/mesos-1.4.0-shaded-protobuf.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/macro-compat_2.12-1.1.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/machinist_2.12-0.6.8.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/lz4-java-1.7.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/logging-interceptor-3.12.12.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/log4j-1.2.17.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/libthrift-0.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/libfb303-0.9.3.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/leveldbjni-all-1.8.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-storageclass-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-settings-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-scheduling-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-rbac-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-policy-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-networking-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-metrics-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-extensions-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-events-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-discovery-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-core-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-coordination-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-common-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-certificates-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-batch-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-autoscaling-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-apps-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-apiextensions-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-model-admissionregistration-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kubernetes-client-4.12.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/kryo-shaded-4.0.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jul-to-slf4j-1.7.30.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jta-1.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jsr305-3.0.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jsp-api-2.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/json4s-scalap_2.12-3.7.0-M5.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/json4s-jackson_2.12-3.7.0-M5.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/json4s-core_2.12-3.7.0-M5.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/json4s-ast_2.12-3.7.0-M5.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/json-1.8.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jpam-1.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jodd-core-3.5.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/joda-time-2.10.5.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jline-2.14.6.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jetty-util-6.1.26.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jetty-sslengine-6.1.26.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jetty-6.1.26.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jersey-server-2.30.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jersey-media-jaxb-2.30.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jersey-hk2-2.30.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jersey-container-servlet-core-2.30.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jersey-container-servlet-2.30.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jersey-common-2.30.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jersey-client-2.30.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jdo-api-3.0.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jcl-over-slf4j-1.7.30.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jaxb-runtime-2.3.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jaxb-api-2.2.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/javolution-5.5.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/javax.jdo-3.2.0-m3.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/javax.inject-1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/javassist-3.25.0-GA.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/janino-3.0.16.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jakarta.xml.bind-api-2.3.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jakarta.ws.rs-api-2.1.6.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jakarta.validation-api-2.0.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jakarta.servlet-api-4.0.3.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jakarta.inject-2.6.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jakarta.annotation-api-1.3.5.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jakarta.activation-api-1.2.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jackson-xc-1.9.13.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jackson-module-scala_2.12-2.10.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jackson-module-paranamer-2.10.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jackson-module-jaxb-annotations-2.10.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jackson-mapper-asl-1.9.13.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jackson-jaxrs-1.9.13.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jackson-datatype-jsr310-2.11.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jackson-dataformat-yaml-2.10.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jackson-databind-2.10.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jackson-core-asl-1.9.13.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jackson-core-2.10.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/jackson-annotations-2.10.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/ivy-2.4.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/istack-commons-runtime-3.0.8.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/httpcore-4.4.12.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/httpclient-4.5.6.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/htrace-core-3.1.0-incubating.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hk2-utils-2.6.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hk2-locator-2.6.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hk2-api-2.6.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-vector-code-gen-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-storage-api-2.7.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-shims-scheduler-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-shims-common-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-shims-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-shims-0.23-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-service-rpc-3.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-serde-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-metastore-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-llap-common-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-jdbc-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-exec-2.3.7-core.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-common-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-cli-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hive-beeline-2.3.7.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-yarn-server-web-proxy-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-yarn-server-common-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-yarn-common-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-yarn-client-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-yarn-api-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-mapreduce-client-shuffle-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-mapreduce-client-jobclient-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-mapreduce-client-core-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-mapreduce-client-common-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-mapreduce-client-app-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-hdfs-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-common-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-client-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-auth-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/hadoop-annotations-2.7.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/guice-servlet-3.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/guice-3.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/guava-14.0.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/gson-2.2.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/generex-1.0.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/flatbuffers-java-1.9.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/derby-10.12.1.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/datanucleus-rdbms-4.1.19.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/datanucleus-core-4.1.17.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/datanucleus-api-jdo-4.2.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/curator-recipes-2.7.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/curator-framework-2.7.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/curator-client-2.7.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/core-1.1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/compress-lzf-1.0.3.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-text-1.6.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-pool-1.5.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-net-3.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-math3-3.4.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-logging-1.1.3.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-lang3-3.10.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-lang-2.6.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-io-2.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-httpclient-3.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-digester-1.8.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-dbcp-1.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-crypto-1.1.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-configuration-1.6.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-compress-1.20.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-compiler-3.0.16.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-collections-3.2.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-codec-1.10.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-cli-1.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/commons-beanutils-1.9.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/chill_2.12-0.9.5.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/chill-java-0.9.5.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/cats-kernel_2.12-2.0.0-M4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/breeze_2.12-1.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/breeze-macros_2.12-1.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/bonecp-0.8.0.RELEASE.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/avro-mapred-1.8.2-hadoop2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/avro-ipc-1.8.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/avro-1.8.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/automaton-1.11-8.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/audience-annotations-0.5.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/arrow-vector-2.0.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/arrow-memory-netty-2.0.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/arrow-memory-core-2.0.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/arrow-format-2.0.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/arpack_combined_all-0.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/api-util-1.0.0-M20.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/api-asn1-api-1.0.0-M20.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/apacheds-kerberos-codec-2.0.0-M15.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/apacheds-i18n-2.0.0-M15.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/aopalliance-repackaged-2.6.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/aopalliance-1.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/antlr4-runtime-4.8-1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/antlr-runtime-3.5.2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/algebra_2.12-2.0.0-M2.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/aircompressor-0.10.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/activation-1.1.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/ST4-4.0.4.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/RoaringBitmap-0.9.0.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/JTransforms-3.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/JLargeArrays-1.5.jar\n",
            "spark-3.1.2-bin-hadoop2.7/jars/HikariCP-2.5.1.jar\n",
            "spark-3.1.2-bin-hadoop2.7/python/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/userlibrary.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/userlib-0.1.zip\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/text-test.txt\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/streaming/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/streaming/text-test.txt\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/people_array_utf16le.json\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/people_array.json\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/people1.json\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/people.json\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/part-r-00007.gz.parquet\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/.part-r-00007.gz.parquet.crc\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/part-r-00005.gz.parquet\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/.part-r-00005.gz.parquet.crc\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00004.gz.parquet\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00002.gz.parquet\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00004.gz.parquet.crc\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00002.gz.parquet.crc\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/part-r-00008.gz.parquet\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/.part-r-00008.gz.parquet.crc\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_metadata\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_common_metadata\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_SUCCESS\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/orc_partitioned/_SUCCESS\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/ages_newlines.csv\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/sql/ages.csv\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/hello/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/hello/sub_hello/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/hello/sub_hello/sub_hello.txt\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/hello/hello.txt\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_support/SimpleHTTPServer.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_coverage/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_coverage/sitecustomize.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_coverage/coverage_daemon.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_coverage/conf/\n",
            "spark-3.1.2-bin-hadoop2.7/python/test_coverage/conf/spark-defaults.conf\n",
            "spark-3.1.2-bin-hadoop2.7/python/setup.cfg\n",
            "spark-3.1.2-bin-hadoop2.7/python/run-tests\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/version.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/util.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/traceback_utils.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_worker.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_util.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_taskcontext.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_shuffle.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_serializers.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_readwrite.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_rddbarrier.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_rdd.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_profiler.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_pin_thread.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_join.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_install_spark.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_daemon.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_context.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_conf.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_broadcast.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/test_appsubmit.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/tests/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/testing/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/testing/streamingutils.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/testing/sqlutils.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/testing/mlutils.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/testing/mllibutils.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/testing/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/testing/utils.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/taskcontext.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/util.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/tests/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/tests/test_listener.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/tests/test_kinesis.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/tests/test_dstream.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/tests/test_context.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/tests/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/listener.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/listener.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/kinesis.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/kinesis.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/dstream.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/context.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/context.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/streaming/dstream.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/storagelevel.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/storagelevel.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/status.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/status.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/statcounter.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/statcounter.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/stat/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/stat/_statistics.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/stat/__init__.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/stat/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/stat/KernelDensity.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/stat/KernelDensity.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/stat/test.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/stat/test.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/stat/distribution.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/stat/distribution.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/stat/_statistics.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/regression.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/recommendation.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/recommendation.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/random.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/random.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/linalg/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/linalg/distributed.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/linalg/__init__.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/linalg/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/linalg/distributed.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/fpm.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/fpm.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/feature.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/feature.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/evaluation.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/evaluation.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/common.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/common.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/clustering.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/classification.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/_typing.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/util.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/util.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/tree.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/tree.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/tests/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/tests/test_util.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/tests/test_streaming_algorithms.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/tests/test_stat.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/tests/test_feature.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/tests/test_algorithms.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/tests/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/tests/test_linalg.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/regression.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/clustering.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/mllib/classification.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/wrapper.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/wrapper.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/util.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/util.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tree.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_wrapper.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_util.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_stat.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_pipeline.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_persistence.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_linalg.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_image.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_feature.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_algorithms.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_tuning.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_training_summary.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_param.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_evaluation.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tests/test_base.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/stat.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/stat.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/regression.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/recommendation.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/pipeline.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/pipeline.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/param/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/param/shared.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/param/shared.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/param/_shared_params_code_gen.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/param/_shared_params_code_gen.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/param/__init__.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/param/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/linalg/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/linalg/__init__.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/linalg/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/image.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/image.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/functions.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/fpm.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/feature.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/evaluation.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/common.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/common.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/clustering.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/classification.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/base.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/_typing.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tuning.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tuning.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/tree.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/regression.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/recommendation.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/functions.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/fpm.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/feature.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/evaluation.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/clustering.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/classification.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/ml/base.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/join.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/java_gateway.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/install.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/find_spark_home.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/files.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/files.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/daemon.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/context.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/context.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/conf.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/conf.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/cloudpickle/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/cloudpickle/compat.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/cloudpickle/cloudpickle_fast.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/cloudpickle/cloudpickle.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/cloudpickle/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/broadcast.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/broadcast.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/accumulators.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/accumulators.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/_typing.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/_globals.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/__init__.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/window.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/window.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/utils.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/udf.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/types.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/types.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_utils.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_udf.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_types.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_streaming.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_session.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_serde.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_readwriter.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_window.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_typehints.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_scalar.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_grouped_agg.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_map.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_cogrouped_map.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_datasources.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_context.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_conf.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_catalog.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_grouped_map.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_group.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_functions.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_dataframe.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_column.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/tests/test_arrow.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/streaming.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/session.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/readwriter.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/utils.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/typehints.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/serializers.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/map_ops.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/map_ops.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/group_ops.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/group_ops.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/functions.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/functions.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/conversion.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/protocols/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/protocols/series.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/protocols/frame.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/protocols/__init__.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/__init__.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/types.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/pandas/conversion.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/group.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/group.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/dataframe.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/context.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/conf.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/conf.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/column.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/catalog.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/avro/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/avro/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/avro/functions.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/avro/functions.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/_typing.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/__init__.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/udf.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/streaming.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/session.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/readwriter.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/functions.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/functions.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/dataframe.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/context.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/column.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/catalog.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/shuffle.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/shell.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/serializers.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/resultiterable.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/resultiterable.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/resource/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/resource/tests/\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/resource/tests/test_resources.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/resource/tests/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/resource/requests.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/resource/requests.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/resource/information.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/resource/information.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/resource/__init__.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/resource/profile.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/resource/profile.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/rddsampler.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/rdd.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/py.typed\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/profiler.pyi\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/profiler.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/worker.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/version.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/taskcontext.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pyspark/rdd.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/pylintrc\n",
            "spark-3.1.2-bin-hadoop2.7/python/lib/\n",
            "spark-3.1.2-bin-hadoop2.7/python/lib/PY4J_LICENSE.txt\n",
            "spark-3.1.2-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip\n",
            "spark-3.1.2-bin-hadoop2.7/python/lib/pyspark.zip\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/user_guide/\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/user_guide/python_packaging.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/user_guide/index.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/user_guide/arrow_pandas.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/reference/\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/reference/pyspark.streaming.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/reference/pyspark.ss.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/reference/pyspark.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/reference/pyspark.resource.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/reference/pyspark.mllib.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/reference/index.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/reference/pyspark.sql.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/reference/pyspark.ml.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/migration_guide/\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_2.3_to_2.4.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_2.3.0_to_2.3.1_above.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_2.2_to_2.3.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_1.4_to_1.5.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_1.0_1.2_to_1.3.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_2.4_to_3.0.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/migration_guide/index.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/getting_started/\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/getting_started/quickstart.ipynb\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/getting_started/index.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/getting_started/install.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/development/\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/development/testing.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/development/setting_ide.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/development/index.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/development/debugging.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/development/contributing.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/_templates/\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/_templates/autosummary/\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/_templates/autosummary/class_with_docs.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/_templates/autosummary/class.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/_static/\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/_static/css/\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/_static/css/pyspark.css\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/_static/copybutton.js\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/index.rst\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/source/conf.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/make.bat\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/make2.bat\n",
            "spark-3.1.2-bin-hadoop2.7/python/docs/Makefile\n",
            "spark-3.1.2-bin-hadoop2.7/python/README.md\n",
            "spark-3.1.2-bin-hadoop2.7/python/MANIFEST.in\n",
            "spark-3.1.2-bin-hadoop2.7/python/.gitignore\n",
            "spark-3.1.2-bin-hadoop2.7/python/.coveragerc\n",
            "spark-3.1.2-bin-hadoop2.7/python/setup.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/run-tests.py\n",
            "spark-3.1.2-bin-hadoop2.7/python/run-tests-with-coverage\n",
            "spark-3.1.2-bin-hadoop2.7/python/mypy.ini\n",
            "spark-3.1.2-bin-hadoop2.7/bin/\n",
            "spark-3.1.2-bin-hadoop2.7/bin/sparkR2.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/sparkR.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/sparkR\n",
            "spark-3.1.2-bin-hadoop2.7/bin/spark-submit2.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/spark-submit.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/spark-submit\n",
            "spark-3.1.2-bin-hadoop2.7/bin/spark-sql2.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/spark-sql.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/spark-sql\n",
            "spark-3.1.2-bin-hadoop2.7/bin/spark-shell2.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/spark-shell.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/spark-shell\n",
            "spark-3.1.2-bin-hadoop2.7/bin/spark-class2.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/spark-class.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/spark-class\n",
            "spark-3.1.2-bin-hadoop2.7/bin/run-example.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/run-example\n",
            "spark-3.1.2-bin-hadoop2.7/bin/pyspark.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/load-spark-env.sh\n",
            "spark-3.1.2-bin-hadoop2.7/bin/load-spark-env.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/find-spark-home.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/find-spark-home\n",
            "spark-3.1.2-bin-hadoop2.7/bin/docker-image-tool.sh\n",
            "spark-3.1.2-bin-hadoop2.7/bin/beeline.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/beeline\n",
            "spark-3.1.2-bin-hadoop2.7/bin/pyspark2.cmd\n",
            "spark-3.1.2-bin-hadoop2.7/bin/pyspark\n",
            "spark-3.1.2-bin-hadoop2.7/README.md\n",
            "spark-3.1.2-bin-hadoop2.7/conf/\n",
            "spark-3.1.2-bin-hadoop2.7/conf/workers.template\n",
            "spark-3.1.2-bin-hadoop2.7/conf/spark-env.sh.template\n",
            "spark-3.1.2-bin-hadoop2.7/conf/spark-defaults.conf.template\n",
            "spark-3.1.2-bin-hadoop2.7/conf/metrics.properties.template\n",
            "spark-3.1.2-bin-hadoop2.7/conf/log4j.properties.template\n",
            "spark-3.1.2-bin-hadoop2.7/conf/fairscheduler.xml.template\n",
            "spark-3.1.2-bin-hadoop2.7/data/\n",
            "spark-3.1.2-bin-hadoop2.7/data/streaming/\n",
            "spark-3.1.2-bin-hadoop2.7/data/streaming/AFINN-111.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/streaming_kmeans_data_test.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/sample_svm_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/sample_multiclass_classification_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/sample_movielens_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/sample_linear_regression_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/sample_libsvm_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/sample_lda_libsvm_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/sample_lda_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/sample_kmeans_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/sample_isotonic_regression_libsvm_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/sample_fpgrowth.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/sample_binary_classification_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/ridge-data/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/ridge-data/lpsa.data\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/pic_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/pagerank_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/kmeans_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/iris_libsvm.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/grayscale.jpg\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/chr30.4.184.jpg\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA_alpha_60.png\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA.png\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP802813.jpg\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP153539.jpg\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/54893.jpg\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/not-image.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/origin/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/origin/multi-channel/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/origin/multi-channel/grayscale.jpg\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/origin/multi-channel/BGRA.png\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/origin/license.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/origin/kittens/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/origin/kittens/not-image.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/origin/kittens/DP802813.jpg\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/origin/kittens/DP153539.jpg\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/origin/kittens/54893.jpg\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/images/license.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/gmm_data.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/als/\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/als/test.data\n",
            "spark-3.1.2-bin-hadoop2.7/data/mllib/als/sample_movielens_ratings.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/graphx/\n",
            "spark-3.1.2-bin-hadoop2.7/data/graphx/users.txt\n",
            "spark-3.1.2-bin-hadoop2.7/data/graphx/followers.txt\n",
            "spark-3.1.2-bin-hadoop2.7/NOTICE\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-zstd.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-zstd-jni.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-xmlenc.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-vis-timeline.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-spire.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-sorttable.js.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-slf4j.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-scopt.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-scala.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-sbt-launch-lib.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-respond.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-reflectasm.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-re2j.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-pyrolite.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-py4j.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-protobuf.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-pmml-model.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-paranamer.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-netlib.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-mustache.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-modernizr.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-minlog.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-matchMedia-polyfill.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-machinist.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-leveldbjni.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-kryo.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-jsp-api.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-json-formatter.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-jquery.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-join.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-jodd.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-jline.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-jaxb-runtime.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-javolution.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-javax-transaction-transaction-api.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-javassist.html\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-janino.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-jakarta.xml.bind-api.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-jakarta.activation-api.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-jakarta-ws-rs-api\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-jakarta-annotation-api\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-istack-commons-runtime.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-graphlib-dot.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-f2j.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-dnsjava.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-datatables.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-dagre-d3.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-d3.min.js.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-cloudpickle.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-bootstrap.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-automaton.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-arpack.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-antlr.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-JTransforms.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-JLargeArrays.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-CC0.txt\n",
            "spark-3.1.2-bin-hadoop2.7/licenses/LICENSE-AnchorJS.txt\n",
            "spark-3.1.2-bin-hadoop2.7/LICENSE\n",
            "spark-3.1.2-bin-hadoop2.7/RELEASE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set enviroment variable ให้ Python รู้จัก Spark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\""
      ],
      "metadata": {
        "id": "AVmc1-E_Uehm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ติดตั้ง PySpark ลงใน Python\n",
        "!pip install pyspark==3.1.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6xkBjlj65wu",
        "outputId": "937b5dde-725a-47b9-afcb-9622c436113b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark==3.1.2\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4 MB 67 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 5.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880769 sha256=857f11298ea90e199f167f69c50902e79b3b7c6d5ddbd7404cb4bff06a8f4a54\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# สร้าง Spark Session เพิ้อใช้งาน Spark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "zv-T6qMY67pn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt = spark.read.csv('/content/sentences.csv', header = True, inferSchema = True, )"
      ],
      "metadata": {
        "id": "YNVFJ_RB7N5R"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HeTZrXQ7iRN",
        "outputId": "7dd28201-de65-4f19-fd19-7d19eb4e26cf"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+--------------------------------------+\n",
            "| id|lan_code|                              sentence|\n",
            "+---+--------+--------------------------------------+\n",
            "|  1|     cmn|                          我們試試看！|\n",
            "|  2|     cmn|                        我该去睡觉了。|\n",
            "|  3|     cmn|                        你在干什麼啊？|\n",
            "|  4|     cmn|                          這是什麼啊？|\n",
            "|  5|     cmn|       今天是６月１８号，也是Muirie...|\n",
            "|  6|     cmn|                   生日快乐，Muiriel！|\n",
            "|  7|     cmn|                   Muiriel现在20岁了。|\n",
            "|  8|     cmn|                 \"密码是\"\"Muiriel\"\"。\"|\n",
            "|  9|     cmn|                      我很快就會回來。|\n",
            "| 10|     cmn|                            我不知道。|\n",
            "| 11|     cmn|              我不知道應該說什麼才好。|\n",
            "| 12|     cmn|                    這個永遠完不了了。|\n",
            "| 13|     cmn|          我只是不知道應該說什麼而已……|\n",
            "| 14|     cmn|                那是一隻有惡意的兔子。|\n",
            "| 15|     cmn|                        我以前在山里。|\n",
            "| 16|     cmn|                      那是一张近照吗？|\n",
            "| 17|     cmn|                我不知道我有沒有時間。|\n",
            "| 18|     cmn|剛才我的麥克風沒起作用，不知道為什麼。|\n",
            "| 19|     cmn|      到了最後，大家一定要靠自己學習。|\n",
            "| 20|     cmn|              世界上的教育都讓我失望。|\n",
            "+---+--------+--------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt.describe().show()"
      ],
      "metadata": {
        "id": "imJwy_Rj8pC1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69d7fe66-7035-4db0-c07b-9cc9ee54ac77"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+--------------------+--------------------+\n",
            "|summary|               id|            lan_code|            sentence|\n",
            "+-------+-----------------+--------------------+--------------------+\n",
            "|  count|         10358184|            10344605|            10342389|\n",
            "|   mean|5456834.004596196|                null|              2018.0|\n",
            "| stddev|3126110.219602189|                null|                null|\n",
            "|    min|                1| 'Can you smile f...| \"\"which would su...|\n",
            "|    max|          9999999|         ” she said.|           𡀲係書。|\n",
            "+-------+-----------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt.filter((dt.lan_code == \"cmn\") | (dt.lan_code == \"jpn\") | (dt.lan_code == \"kor\") | (dt.lan_code == \"tha\")).describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ1CSSta8LCv",
        "outputId": "427c23af-291f-4a35-c1eb-622e39d4f5c4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+--------+-----------------------------------+\n",
            "|summary|                id|lan_code|                           sentence|\n",
            "+-------+------------------+--------+-----------------------------------+\n",
            "|  count|            306274|  306274|                             306274|\n",
            "|   mean|2562487.7549514486|    null|                               null|\n",
            "| stddev| 3610521.918777409|    null|                               null|\n",
            "|    min|                 1|     cmn| 我已經長大了不玩蟲了，這個男孩說。|\n",
            "|    max|             99999|     tha|                       𠮟っとくよ。|\n",
            "+-------+------------------+--------+-----------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt.filter(dt.lan_code == \"kor\").describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVMvAdJaCa39",
        "outputId": "8f5998c4-eb2a-4058-9e32-f8649f34280e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+--------+-----------------------------+\n",
            "|summary|               id|lan_code|                     sentence|\n",
            "+-------+-----------------+--------+-----------------------------+\n",
            "|  count|             8981|    8981|                         8981|\n",
            "|   mean|6806475.127045986|    null|                         null|\n",
            "| stddev|3056695.721349035|    null|                         null|\n",
            "|    min|         10008440|     kor|\" 톰은 좀 어때? 마음을 좀 ...|\n",
            "|    max|           998746|     kor|                 힘이 정의다.|\n",
            "+-------+-----------------+--------+-----------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vI013Io_pES",
        "outputId": "e3df62a2-e16d-4e87-862e-7bfa0a813431"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- lan_code: string (nullable = true)\n",
            " |-- sentence: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# final_dt =  dt.filter((dt.lan_code == \"cmn\") | (dt.lan_code == \"jpn\") | (dt.lan_code == \"kor\") | (dt.lan_code == \"tha\"))\n",
        "final_dt =  dt.filter(dt.lan_code == \"tha\")"
      ],
      "metadata": {
        "id": "cO_xzrV6Cthz"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dt.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk0_dpsxFmBB",
        "outputId": "cc159dee-5d7f-4427-9fb3-0e39745b6db1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+--------+--------------------+\n",
            "|summary|                id|lan_code|            sentence|\n",
            "+-------+------------------+--------+--------------------+\n",
            "|  count|              4751|    4751|                4751|\n",
            "|   mean| 8376872.311302884|    null|                null|\n",
            "| stddev|2218164.9307905426|    null|                null|\n",
            "|    min|          10064258|     tha|\"ขอบคุณ \"\"ไม่เป็น...|\n",
            "|    max|            983686|     tha|ไวรัสกำลังแพร่กระ...|\n",
            "+-------+------------------+--------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdfinal = final_dt.toPandas()"
      ],
      "metadata": {
        "id": "8xBnjg7dFph8"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdfinal.to_csv(\"output.csv\")"
      ],
      "metadata": {
        "id": "SEBEU_yQGJsq"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdfinal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "lHW7KEgGGWVg",
        "outputId": "1eb45d04-a4fc-4e27-cecc-74188f358c36"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            id lan_code                                       sentence\n",
              "0       477173      tha                          คุณแต่งงานแล้วหรือยัง\n",
              "1       477178      tha               ภาษาไทยเป็นภาษาราชการในประเทศไทย\n",
              "2       477604      tha                        ผมอ่านเดอะนิวยอร์กไทมส์\n",
              "3       477650      tha                                       ลองทำดู!\n",
              "4       478296      tha                              ภาษาเดียวไม่เคยพอ\n",
              "...        ...      ...                                            ...\n",
              "4746  10777086      tha  ฉันคิดว่าทอมและแมรีกำลังขายอะไรสักอย่างให้เรา\n",
              "4747  10777087      tha                              ทอมซื้อขนมปังอยู่\n",
              "4748  10777088      tha                        ถึงเวลาเริ่มพิธีการแล้ว\n",
              "4749  10777089      tha                               พวกเขาดูตื่นตาใจ\n",
              "4750  10789622      tha  ฉันพอแล้วกับความยากจนต่อต้านวิทยาศาสตร์ของคุณ\n",
              "\n",
              "[4751 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59917858-68a4-4e66-a266-7ddee82cf88c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>lan_code</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>477173</td>\n",
              "      <td>tha</td>\n",
              "      <td>คุณแต่งงานแล้วหรือยัง</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>477178</td>\n",
              "      <td>tha</td>\n",
              "      <td>ภาษาไทยเป็นภาษาราชการในประเทศไทย</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>477604</td>\n",
              "      <td>tha</td>\n",
              "      <td>ผมอ่านเดอะนิวยอร์กไทมส์</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>477650</td>\n",
              "      <td>tha</td>\n",
              "      <td>ลองทำดู!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>478296</td>\n",
              "      <td>tha</td>\n",
              "      <td>ภาษาเดียวไม่เคยพอ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4746</th>\n",
              "      <td>10777086</td>\n",
              "      <td>tha</td>\n",
              "      <td>ฉันคิดว่าทอมและแมรีกำลังขายอะไรสักอย่างให้เรา</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4747</th>\n",
              "      <td>10777087</td>\n",
              "      <td>tha</td>\n",
              "      <td>ทอมซื้อขนมปังอยู่</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4748</th>\n",
              "      <td>10777088</td>\n",
              "      <td>tha</td>\n",
              "      <td>ถึงเวลาเริ่มพิธีการแล้ว</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4749</th>\n",
              "      <td>10777089</td>\n",
              "      <td>tha</td>\n",
              "      <td>พวกเขาดูตื่นตาใจ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4750</th>\n",
              "      <td>10789622</td>\n",
              "      <td>tha</td>\n",
              "      <td>ฉันพอแล้วกับความยากจนต่อต้านวิทยาศาสตร์ของคุณ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4751 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59917858-68a4-4e66-a266-7ddee82cf88c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-59917858-68a4-4e66-a266-7ddee82cf88c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-59917858-68a4-4e66-a266-7ddee82cf88c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_l2l.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMZoVGj5GkJL",
        "outputId": "9876c365-da43-4183-8131-8d56461e8e2a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "country    object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_l2l = df_l2l.reset_index().rename(columns={\"index\": \"code\"})\n",
        "df_l2l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "YSwkFD8qHLia",
        "outputId": "6086baac-d874-4844-f43d-c9f5b624002f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    code                      country\n",
              "0    abk                    Abkhazian\n",
              "1    acm          Mesopotamian Arabic\n",
              "2    ady                       Adyghe\n",
              "3    afb                  Gulf Arabic\n",
              "4    afh                     Afrihili\n",
              "..   ...                          ...\n",
              "399  zgh  Standard Moroccan Tamazight\n",
              "400  zlm  Malay (individual language)\n",
              "401  zsm               Standard Malay\n",
              "402  zul                         Zulu\n",
              "403  zza                         Zaza\n",
              "\n",
              "[404 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7af73fba-2220-409a-a7d2-fe08e8b1650d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>abk</td>\n",
              "      <td>Abkhazian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>acm</td>\n",
              "      <td>Mesopotamian Arabic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ady</td>\n",
              "      <td>Adyghe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>afb</td>\n",
              "      <td>Gulf Arabic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>afh</td>\n",
              "      <td>Afrihili</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>zgh</td>\n",
              "      <td>Standard Moroccan Tamazight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400</th>\n",
              "      <td>zlm</td>\n",
              "      <td>Malay (individual language)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>401</th>\n",
              "      <td>zsm</td>\n",
              "      <td>Standard Malay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>zul</td>\n",
              "      <td>Zulu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>403</th>\n",
              "      <td>zza</td>\n",
              "      <td>Zaza</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>404 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7af73fba-2220-409a-a7d2-fe08e8b1650d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7af73fba-2220-409a-a7d2-fe08e8b1650d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7af73fba-2220-409a-a7d2-fe08e8b1650d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pdfinal.merge(df_l2l, how=\"left\", left_on=\"lan_code\", right_on=\"code\")"
      ],
      "metadata": {
        "id": "AdfBICjlHZsx"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jZJjlrvxHjlQ",
        "outputId": "fbf23e7c-7805-492d-c2a5-8006b7b4bccc"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            id lan_code                                       sentence code  \\\n",
              "0       477173      tha                          คุณแต่งงานแล้วหรือยัง  tha   \n",
              "1       477178      tha               ภาษาไทยเป็นภาษาราชการในประเทศไทย  tha   \n",
              "2       477604      tha                        ผมอ่านเดอะนิวยอร์กไทมส์  tha   \n",
              "3       477650      tha                                       ลองทำดู!  tha   \n",
              "4       478296      tha                              ภาษาเดียวไม่เคยพอ  tha   \n",
              "...        ...      ...                                            ...  ...   \n",
              "4746  10777086      tha  ฉันคิดว่าทอมและแมรีกำลังขายอะไรสักอย่างให้เรา  tha   \n",
              "4747  10777087      tha                              ทอมซื้อขนมปังอยู่  tha   \n",
              "4748  10777088      tha                        ถึงเวลาเริ่มพิธีการแล้ว  tha   \n",
              "4749  10777089      tha                               พวกเขาดูตื่นตาใจ  tha   \n",
              "4750  10789622      tha  ฉันพอแล้วกับความยากจนต่อต้านวิทยาศาสตร์ของคุณ  tha   \n",
              "\n",
              "     country  \n",
              "0       Thai  \n",
              "1       Thai  \n",
              "2       Thai  \n",
              "3       Thai  \n",
              "4       Thai  \n",
              "...      ...  \n",
              "4746    Thai  \n",
              "4747    Thai  \n",
              "4748    Thai  \n",
              "4749    Thai  \n",
              "4750    Thai  \n",
              "\n",
              "[4751 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3fab4721-f39f-44cb-b106-754cf082028e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>lan_code</th>\n",
              "      <th>sentence</th>\n",
              "      <th>code</th>\n",
              "      <th>country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>477173</td>\n",
              "      <td>tha</td>\n",
              "      <td>คุณแต่งงานแล้วหรือยัง</td>\n",
              "      <td>tha</td>\n",
              "      <td>Thai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>477178</td>\n",
              "      <td>tha</td>\n",
              "      <td>ภาษาไทยเป็นภาษาราชการในประเทศไทย</td>\n",
              "      <td>tha</td>\n",
              "      <td>Thai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>477604</td>\n",
              "      <td>tha</td>\n",
              "      <td>ผมอ่านเดอะนิวยอร์กไทมส์</td>\n",
              "      <td>tha</td>\n",
              "      <td>Thai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>477650</td>\n",
              "      <td>tha</td>\n",
              "      <td>ลองทำดู!</td>\n",
              "      <td>tha</td>\n",
              "      <td>Thai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>478296</td>\n",
              "      <td>tha</td>\n",
              "      <td>ภาษาเดียวไม่เคยพอ</td>\n",
              "      <td>tha</td>\n",
              "      <td>Thai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4746</th>\n",
              "      <td>10777086</td>\n",
              "      <td>tha</td>\n",
              "      <td>ฉันคิดว่าทอมและแมรีกำลังขายอะไรสักอย่างให้เรา</td>\n",
              "      <td>tha</td>\n",
              "      <td>Thai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4747</th>\n",
              "      <td>10777087</td>\n",
              "      <td>tha</td>\n",
              "      <td>ทอมซื้อขนมปังอยู่</td>\n",
              "      <td>tha</td>\n",
              "      <td>Thai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4748</th>\n",
              "      <td>10777088</td>\n",
              "      <td>tha</td>\n",
              "      <td>ถึงเวลาเริ่มพิธีการแล้ว</td>\n",
              "      <td>tha</td>\n",
              "      <td>Thai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4749</th>\n",
              "      <td>10777089</td>\n",
              "      <td>tha</td>\n",
              "      <td>พวกเขาดูตื่นตาใจ</td>\n",
              "      <td>tha</td>\n",
              "      <td>Thai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4750</th>\n",
              "      <td>10789622</td>\n",
              "      <td>tha</td>\n",
              "      <td>ฉันพอแล้วกับความยากจนต่อต้านวิทยาศาสตร์ของคุณ</td>\n",
              "      <td>tha</td>\n",
              "      <td>Thai</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4751 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3fab4721-f39f-44cb-b106-754cf082028e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3fab4721-f39f-44cb-b106-754cf082028e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3fab4721-f39f-44cb-b106-754cf082028e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = final_df.drop(\"code\", axis=1)"
      ],
      "metadata": {
        "id": "BDxi4x4UHrbe"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "2ZMt13ioH6K2",
        "outputId": "0e0e69e9-93a5-4560-dc26-9f88334bd4be"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            id lan_code                                       sentence country\n",
              "0       477173      tha                          คุณแต่งงานแล้วหรือยัง    Thai\n",
              "1       477178      tha               ภาษาไทยเป็นภาษาราชการในประเทศไทย    Thai\n",
              "2       477604      tha                        ผมอ่านเดอะนิวยอร์กไทมส์    Thai\n",
              "3       477650      tha                                       ลองทำดู!    Thai\n",
              "4       478296      tha                              ภาษาเดียวไม่เคยพอ    Thai\n",
              "...        ...      ...                                            ...     ...\n",
              "4746  10777086      tha  ฉันคิดว่าทอมและแมรีกำลังขายอะไรสักอย่างให้เรา    Thai\n",
              "4747  10777087      tha                              ทอมซื้อขนมปังอยู่    Thai\n",
              "4748  10777088      tha                        ถึงเวลาเริ่มพิธีการแล้ว    Thai\n",
              "4749  10777089      tha                               พวกเขาดูตื่นตาใจ    Thai\n",
              "4750  10789622      tha  ฉันพอแล้วกับความยากจนต่อต้านวิทยาศาสตร์ของคุณ    Thai\n",
              "\n",
              "[4751 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-943939bf-89f4-4e72-8185-22f5fa4d3791\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>lan_code</th>\n",
              "      <th>sentence</th>\n",
              "      <th>country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>477173</td>\n",
              "      <td>tha</td>\n",
              "      <td>คุณแต่งงานแล้วหรือยัง</td>\n",
              "      <td>Thai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>477178</td>\n",
              "      <td>tha</td>\n",
              "      <td>ภาษาไทยเป็นภาษาราชการในประเทศไทย</td>\n",
              "      <td>Thai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>477604</td>\n",
              "      <td>tha</td>\n",
              "      <td>ผมอ่านเดอะนิวยอร์กไทมส์</td>\n",
              "      <td>Thai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>477650</td>\n",
              "      <td>tha</td>\n",
              "      <td>ลองทำดู!</td>\n",
              "      <td>Thai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>478296</td>\n",
              "      <td>tha</td>\n",
              "      <td>ภาษาเดียวไม่เคยพอ</td>\n",
              "      <td>Thai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4746</th>\n",
              "      <td>10777086</td>\n",
              "      <td>tha</td>\n",
              "      <td>ฉันคิดว่าทอมและแมรีกำลังขายอะไรสักอย่างให้เรา</td>\n",
              "      <td>Thai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4747</th>\n",
              "      <td>10777087</td>\n",
              "      <td>tha</td>\n",
              "      <td>ทอมซื้อขนมปังอยู่</td>\n",
              "      <td>Thai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4748</th>\n",
              "      <td>10777088</td>\n",
              "      <td>tha</td>\n",
              "      <td>ถึงเวลาเริ่มพิธีการแล้ว</td>\n",
              "      <td>Thai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4749</th>\n",
              "      <td>10777089</td>\n",
              "      <td>tha</td>\n",
              "      <td>พวกเขาดูตื่นตาใจ</td>\n",
              "      <td>Thai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4750</th>\n",
              "      <td>10789622</td>\n",
              "      <td>tha</td>\n",
              "      <td>ฉันพอแล้วกับความยากจนต่อต้านวิทยาศาสตร์ของคุณ</td>\n",
              "      <td>Thai</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4751 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-943939bf-89f4-4e72-8185-22f5fa4d3791')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-943939bf-89f4-4e72-8185-22f5fa4d3791 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-943939bf-89f4-4e72-8185-22f5fa4d3791');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df[\"tran_code\"] = final_df[\"lan_code\"]"
      ],
      "metadata": {
        "id": "Zp9aGpyE_iNM"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cmn = zh-CN\n",
        "jpn = ja\n",
        "kor = ko\n",
        "tha = th"
      ],
      "metadata": {
        "id": "EnqUztFEJplw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **ยิ่งข้อมูลเยอะยิ่งใช้เวลาในการแปลนานขึ้น ในนี้เลยทดลองแปลแค่ภาษาไทย\n",
        "(4751 แถว ใช้เวลาประมาณ 1.30 ชั่วโมง)**"
      ],
      "metadata": {
        "id": "d629RF1zUKXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# converter = lambda x : x*2 if x < 10 else (x*3 if x < 20 else x)\n",
        "\n",
        "# final_df[\"tran_code\"] = final_df.apply(lambda x: x[\"lan_code\"].replace(\"cmn\", \"zh-CN\") if x[\"lan_code\"] == \"cmn\" else (x[\"lan_code\"].replace(\"jpn\", \"jp\") if x[\"lan_code\"] == \"jpn\") else (x[\"lan_code\"].replace(\"kor\", \"ko\") if x[\"lan_code\"] == \"kor\") else (x[\"lan_code\"].replace(\"tha\", \"th\") if x[\"lan_code\"] == \"tha\") else None)\n",
        "# final_df[\"tran_code\"] = final_df.apply(lambda x: x[\"tran_code\"].replace(\"cmn\", \"zh-CN\"), axis=1)\n",
        "\n",
        "# final_df[\"tran_code\"] = final_df.apply(lambda x: x[\"tran_code\"].replace(\"jpn\", \"jp\"), axis=1)\n",
        "# final_df[\"tran_code\"] = final_df.apply(lambda x: x[\"tran_code\"].replace(\"kor\", \"ko\"), axis=1)\n",
        "final_df[\"tran_code\"] = final_df.apply(lambda x: x[\"tran_code\"].replace(\"tha\", \"th\"), axis=1)"
      ],
      "metadata": {
        "id": "2Udx9NmwH73G"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "zz2pcjRYKbQg",
        "outputId": "58bed89f-bb58-4b0c-9845-4cbef0ab36d9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            id lan_code                                       sentence  \\\n",
              "0       477173      tha                          คุณแต่งงานแล้วหรือยัง   \n",
              "1       477178      tha               ภาษาไทยเป็นภาษาราชการในประเทศไทย   \n",
              "2       477604      tha                        ผมอ่านเดอะนิวยอร์กไทมส์   \n",
              "3       477650      tha                                       ลองทำดู!   \n",
              "4       478296      tha                              ภาษาเดียวไม่เคยพอ   \n",
              "...        ...      ...                                            ...   \n",
              "4746  10777086      tha  ฉันคิดว่าทอมและแมรีกำลังขายอะไรสักอย่างให้เรา   \n",
              "4747  10777087      tha                              ทอมซื้อขนมปังอยู่   \n",
              "4748  10777088      tha                        ถึงเวลาเริ่มพิธีการแล้ว   \n",
              "4749  10777089      tha                               พวกเขาดูตื่นตาใจ   \n",
              "4750  10789622      tha  ฉันพอแล้วกับความยากจนต่อต้านวิทยาศาสตร์ของคุณ   \n",
              "\n",
              "     country tran_code  \n",
              "0       Thai        th  \n",
              "1       Thai        th  \n",
              "2       Thai        th  \n",
              "3       Thai        th  \n",
              "4       Thai        th  \n",
              "...      ...       ...  \n",
              "4746    Thai        th  \n",
              "4747    Thai        th  \n",
              "4748    Thai        th  \n",
              "4749    Thai        th  \n",
              "4750    Thai        th  \n",
              "\n",
              "[4751 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-962a4cea-49a5-4b3c-919b-887da682d08c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>lan_code</th>\n",
              "      <th>sentence</th>\n",
              "      <th>country</th>\n",
              "      <th>tran_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>477173</td>\n",
              "      <td>tha</td>\n",
              "      <td>คุณแต่งงานแล้วหรือยัง</td>\n",
              "      <td>Thai</td>\n",
              "      <td>th</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>477178</td>\n",
              "      <td>tha</td>\n",
              "      <td>ภาษาไทยเป็นภาษาราชการในประเทศไทย</td>\n",
              "      <td>Thai</td>\n",
              "      <td>th</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>477604</td>\n",
              "      <td>tha</td>\n",
              "      <td>ผมอ่านเดอะนิวยอร์กไทมส์</td>\n",
              "      <td>Thai</td>\n",
              "      <td>th</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>477650</td>\n",
              "      <td>tha</td>\n",
              "      <td>ลองทำดู!</td>\n",
              "      <td>Thai</td>\n",
              "      <td>th</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>478296</td>\n",
              "      <td>tha</td>\n",
              "      <td>ภาษาเดียวไม่เคยพอ</td>\n",
              "      <td>Thai</td>\n",
              "      <td>th</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4746</th>\n",
              "      <td>10777086</td>\n",
              "      <td>tha</td>\n",
              "      <td>ฉันคิดว่าทอมและแมรีกำลังขายอะไรสักอย่างให้เรา</td>\n",
              "      <td>Thai</td>\n",
              "      <td>th</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4747</th>\n",
              "      <td>10777087</td>\n",
              "      <td>tha</td>\n",
              "      <td>ทอมซื้อขนมปังอยู่</td>\n",
              "      <td>Thai</td>\n",
              "      <td>th</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4748</th>\n",
              "      <td>10777088</td>\n",
              "      <td>tha</td>\n",
              "      <td>ถึงเวลาเริ่มพิธีการแล้ว</td>\n",
              "      <td>Thai</td>\n",
              "      <td>th</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4749</th>\n",
              "      <td>10777089</td>\n",
              "      <td>tha</td>\n",
              "      <td>พวกเขาดูตื่นตาใจ</td>\n",
              "      <td>Thai</td>\n",
              "      <td>th</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4750</th>\n",
              "      <td>10789622</td>\n",
              "      <td>tha</td>\n",
              "      <td>ฉันพอแล้วกับความยากจนต่อต้านวิทยาศาสตร์ของคุณ</td>\n",
              "      <td>Thai</td>\n",
              "      <td>th</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4751 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-962a4cea-49a5-4b3c-919b-887da682d08c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-962a4cea-49a5-4b3c-919b-887da682d08c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-962a4cea-49a5-4b3c-919b-887da682d08c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# phrase = 'ฉันพอแล้วกับความยากจนต่อต้านวิทยาศาสตร์ของคุณ\t\t'\n",
        "# ts.google(phrase, from_language='th', to_language='en')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AaWC7RyNLShQ",
        "outputId": "8477681b-8905-450f-cea3-8de59d07aa19"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I am enough with the poverty against your science.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df[\"tran_code\"].unique()"
      ],
      "metadata": {
        "id": "kU7sQv2FDrOJ",
        "outputId": "ecbfc37d-bc60-4e0a-9855-818d8072f943",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['th'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df['to_Eng'] = final_df.apply(lambda x: ts.google(x[\"sentence\"], from_language=x[\"tran_code\"], to_language='en') ,axis=1)"
      ],
      "metadata": {
        "id": "Dov6M-GlJgNI"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df"
      ],
      "metadata": {
        "id": "h6t5QDgpTTYe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "283e1021-2a3b-4818-f046-a89e754efa01"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            id lan_code                                       sentence  \\\n",
              "0       477173      tha                          คุณแต่งงานแล้วหรือยัง   \n",
              "1       477178      tha               ภาษาไทยเป็นภาษาราชการในประเทศไทย   \n",
              "2       477604      tha                        ผมอ่านเดอะนิวยอร์กไทมส์   \n",
              "3       477650      tha                                       ลองทำดู!   \n",
              "4       478296      tha                              ภาษาเดียวไม่เคยพอ   \n",
              "...        ...      ...                                            ...   \n",
              "4746  10777086      tha  ฉันคิดว่าทอมและแมรีกำลังขายอะไรสักอย่างให้เรา   \n",
              "4747  10777087      tha                              ทอมซื้อขนมปังอยู่   \n",
              "4748  10777088      tha                        ถึงเวลาเริ่มพิธีการแล้ว   \n",
              "4749  10777089      tha                               พวกเขาดูตื่นตาใจ   \n",
              "4750  10789622      tha  ฉันพอแล้วกับความยากจนต่อต้านวิทยาศาสตร์ของคุณ   \n",
              "\n",
              "     country tran_code                                             to_Eng  \n",
              "0       Thai        th                                   Are you married?  \n",
              "1       Thai        th           Thai is a official language in Thailand.  \n",
              "2       Thai        th                         I read The New York Times.  \n",
              "3       Thai        th                                      Try to do it!  \n",
              "4       Thai        th                      One language is never enough.  \n",
              "...      ...       ...                                                ...  \n",
              "4746    Thai        th  I think Tom and Mary are selling something to us.  \n",
              "4747    Thai        th                                   Tom bought bread  \n",
              "4748    Thai        th                   It's time to start the ceremony.  \n",
              "4749    Thai        th                           They seem to be dazzled.  \n",
              "4750    Thai        th  I am enough with the poverty against your scie...  \n",
              "\n",
              "[4751 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8d4214d-d729-4f8a-a0b0-e15ce67c3ee5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>lan_code</th>\n",
              "      <th>sentence</th>\n",
              "      <th>country</th>\n",
              "      <th>tran_code</th>\n",
              "      <th>to_Eng</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>477173</td>\n",
              "      <td>tha</td>\n",
              "      <td>คุณแต่งงานแล้วหรือยัง</td>\n",
              "      <td>Thai</td>\n",
              "      <td>th</td>\n",
              "      <td>Are you married?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>477178</td>\n",
              "      <td>tha</td>\n",
              "      <td>ภาษาไทยเป็นภาษาราชการในประเทศไทย</td>\n",
              "      <td>Thai</td>\n",
              "      <td>th</td>\n",
              "      <td>Thai is a official language in Thailand.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>477604</td>\n",
              "      <td>tha</td>\n",
              "      <td>ผมอ่านเดอะนิวยอร์กไทมส์</td>\n",
              "      <td>Thai</td>\n",
              "      <td>th</td>\n",
              "      <td>I read The New York Times.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>477650</td>\n",
              "      <td>tha</td>\n",
              "      <td>ลองทำดู!</td>\n",
              "      <td>Thai</td>\n",
              "      <td>th</td>\n",
              "      <td>Try to do it!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>478296</td>\n",
              "      <td>tha</td>\n",
              "      <td>ภาษาเดียวไม่เคยพอ</td>\n",
              "      <td>Thai</td>\n",
              "      <td>th</td>\n",
              "      <td>One language is never enough.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4746</th>\n",
              "      <td>10777086</td>\n",
              "      <td>tha</td>\n",
              "      <td>ฉันคิดว่าทอมและแมรีกำลังขายอะไรสักอย่างให้เรา</td>\n",
              "      <td>Thai</td>\n",
              "      <td>th</td>\n",
              "      <td>I think Tom and Mary are selling something to us.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4747</th>\n",
              "      <td>10777087</td>\n",
              "      <td>tha</td>\n",
              "      <td>ทอมซื้อขนมปังอยู่</td>\n",
              "      <td>Thai</td>\n",
              "      <td>th</td>\n",
              "      <td>Tom bought bread</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4748</th>\n",
              "      <td>10777088</td>\n",
              "      <td>tha</td>\n",
              "      <td>ถึงเวลาเริ่มพิธีการแล้ว</td>\n",
              "      <td>Thai</td>\n",
              "      <td>th</td>\n",
              "      <td>It's time to start the ceremony.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4749</th>\n",
              "      <td>10777089</td>\n",
              "      <td>tha</td>\n",
              "      <td>พวกเขาดูตื่นตาใจ</td>\n",
              "      <td>Thai</td>\n",
              "      <td>th</td>\n",
              "      <td>They seem to be dazzled.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4750</th>\n",
              "      <td>10789622</td>\n",
              "      <td>tha</td>\n",
              "      <td>ฉันพอแล้วกับความยากจนต่อต้านวิทยาศาสตร์ของคุณ</td>\n",
              "      <td>Thai</td>\n",
              "      <td>th</td>\n",
              "      <td>I am enough with the poverty against your scie...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4751 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8d4214d-d729-4f8a-a0b0-e15ce67c3ee5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d8d4214d-d729-4f8a-a0b0-e15ce67c3ee5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d8d4214d-d729-4f8a-a0b0-e15ce67c3ee5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.to_csv(\"To_Eng_output.csv\")"
      ],
      "metadata": {
        "id": "nVf2ToR2U2jl"
      },
      "execution_count": 49,
      "outputs": []
    }
  ]
}